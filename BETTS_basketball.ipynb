{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a175191e",
   "metadata": {},
   "source": [
    "# Adding INLA (R required)\n",
    "https://claude.ai/chat/2ea12d21-5d52-4dc5-ae51-e05c1edf0e90\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3f3ff",
   "metadata": {},
   "source": [
    "# Use Team PIE for team win rankings (possibly by player leading up to team pie for more detailed analysis)\n",
    "\n",
    "\n",
    "| Model / source                                         | Primary Y variable(s)                                        | Task type                                         | Key notes / proof                                                                                              |\n",
    "| ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n",
    "| **Zhao et al. (2023) – GCN**                           | **Game outcome (win/loss)**                                  | Binary classification                             | “Predicting the outcome of games… average success rate” → binary W/L. ([PMC][1])                               |\n",
    "| **He & Choi (2025) – Stacked ensemble**                | **Game outcome (win/loss)**                                  | Binary classification                             | Paper explicitly “predict the outcomes of NBA games.” ([PMC][2], [Nature][3])                                  |\n",
    "| **Osken & Onay (2022) – Player clusters + ANN**        | **Winning team (win/loss)**                                  | Binary classification                             | “We achieve… accuracy… predicting the winning team.” ([PubMed][4], [ScienceDirect][5])                         |\n",
    "| **KNN baselines (surveyed)**                           | **Win/loss (sometimes score)**                               | Binary classification (and some score regression) | Reviews describe supervised setups for **win/loss**; some studies also model **scores**. ([PLOS][6], [PMC][7]) |\n",
    "| **Chen et al. (2021) – Hybrid ensemble**               | **Final score (points)**                                     | Regression (team points; then derive winner)      | “Predicting the final score of NBA games.” ([MDPI][8])                                                         |\n",
    "| **ESPN BPI**                                           | **Win probability** (per game) and **projected margin**      | Probabilistic classification + regression         | BPI “produces a team’s percentage to win any game” and projects **margin of victory**. ([ESPN.com][9])         |\n",
    "| **In-game WP models (e.g., ESPN; Inpredictable eval)** | **Instantaneous win probability** (scored vs. final outcome) | Probabilistic time-series                         | Forecasts are calibrated so that end-of-game **outcome (0/1)** is the scoring label. ([inpredictable][10])     |\n",
    "Where PIE fits (as Y or as a latent target)\n",
    "\n",
    "What PIE is: a share-of-events metric—“what % of game events a player/team contributed,” with a published formula. \n",
    "NBAstuffer\n",
    "\n",
    "Team PIE ↔ winning: NBA’s own FAQ says team PIE correlates strongly with win% (R² ≈ 0.908) and “>50% is likely a winning team.” \n",
    "NBA\n",
    "\n",
    "Should you make PIE the Y?\n",
    "\n",
    "For game prediction, the literature overwhelmingly uses win/loss, win probability, margin, or score as Y (table above). PIE is not commonly used as the final target.\n",
    "\n",
    "PIE can be powerful as a latent/intermediate target that feeds your final Y:\n",
    "\n",
    "Two practical designs\n",
    "\n",
    "Two-stage model (recommended):\n",
    "\n",
    "Stage A (hierarchical): predict team PIE from player-level PIE contributions with partial pooling across players/lineups/opponents (Bayesian hierarchical regression).\n",
    "\n",
    "Stage B (link): map predicted team PIE (or PIE differential) to win probability via a learned monotonic link (logistic or isotonic).\n",
    "\n",
    "Why: preserves interpretability of player contributions while ending with a decision-ready probability.\n",
    "\n",
    "Direct model with PIE as feature:\n",
    "\n",
    "Predict win/loss or margin directly, but include current/expected team PIE (built up from player PIE priors and injury/rotation context) as a top feature.\n",
    "\n",
    "When to favor player-to-team PIE build-up\n",
    "\n",
    "Early season / new lineups / injuries, where you need shrinkage and principled uncertainty across players → hierarchical PIE stage stabilizes estimates before you predict W/L.\n",
    "\n",
    "Quick guidance for your experiment\n",
    "\n",
    "If your goal is game outcomes: set Y = win probability (or win/loss) and treat player PIE → team PIE as X (features) or as a latent stage feeding the classifier.\n",
    "\n",
    "If your goal is explaining performance: you can set Y = team PIE and analyze how player PIE and context drive it, but you’ll still want a final mapping to W/L for evaluation against the field.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b2f97",
   "metadata": {},
   "source": [
    "https://claude.ai/chat/2992e47f-1455-43c3-ad0c-e134826129f2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ffe69",
   "metadata": {},
   "source": [
    "Thanks for sharing your detailed summary! I looked into the web to verify accuracy. Here's what I found—and what should *not* be included due to lack of evidence or contradictory findings.\n",
    "\n",
    "---\n",
    "\n",
    "### **What’s Fully Supported by Verified Sources**\n",
    "\n",
    "* **Graph Convolutional Networks (GCNs) + Random Forest achieved \\~71.54% accuracy** in NBA game outcome prediction (2012–2018 data) — supported by studies including Zhao et al. (2023) and others ([Nature][1]).\n",
    "\n",
    "* **Osken & Onay’s ANN-based model** (using player clustering) reported \\~76% accuracy across several NBA seasons ([Nature][1]).\n",
    "\n",
    "* **Espn’s BPI calibration performance** is well documented: teams with 50–60% projected chance of winning won about 55.8% of those games, and BPI favorites have won \\~75.6% of games ([ESPN.com][2]).\n",
    "\n",
    "* **KNN performance**: around 60–61% accuracy on NBA game outcomes ([Nature][1]).\n",
    "\n",
    "---\n",
    "\n",
    "### **What Remains Unverified or Unsupported**\n",
    "\n",
    "Claims such as:\n",
    "\n",
    "* **“ESPN BPI overall accuracy = 68.9%”**\n",
    "* **“BPI success rate 74.9% for teams >50% win probability in 2024–25”**\n",
    "* **“Raw accuracy ranges 65–80% across 2024–25 models”**\n",
    "* **“XGBoost + SHAP models reaching 78% accuracy”**\n",
    "* **“Transformer‑based models, real-time calibration improvements of 15–20 percentage points,” or “Bayesian hierarchical EPAA frameworks” with superior uncertainty quantification**\n",
    "* **“Commercial claims like Stats Insider or etc.”**\n",
    "\n",
    "—have no corroborating evidence from available academic or public sources.\n",
    "\n",
    "---\n",
    "\n",
    "### **Clean, Accurate Table**\n",
    "\n",
    "Below is an **easy‑to‑read table** using only verified information. I have left blank any entries where claims cannot be substantiated with citations.\n",
    "\n",
    "| Model / Methodology                                                                                                                              | Accuracy / Performance              | Notes / Source                                                                                                |\n",
    "| ------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
    "| GCN + Random Forest (Zhao et al., 2023)                                                                                                          | **71.54 %**                         | GCN + RF fusion on NBA data (2012–2018) ([PLOS][3], [ResearchGate][4], [ESPN.com][2], [PLOS][5], [Nature][1]) |\n",
    "| ANN with player clustering (Osken & Onay)                                                                                                        | **≈76 %**                           | Clustering + ANN across five NBA seasons ([ResearchGate][4], [Nature][1])                                     |\n",
    "| ESPN BPI calibration (50–60% range)                                                                                                              | Teams won **55.8 %** of those games | BPI’s probability calibration ([ESPN.com][2])                                                                 |\n",
    "| BPI favorites overall win rate                                                                                                                   | **≈75.6 %**                         | Historical BPI success rate ([ESPN.com][2])                                                                   |\n",
    "| K-Nearest Neighbors (KNN)                                                                                                                        | **\\~60.0–61 %**                     | KNN predictive accuracy in NBA outcomes ([Nature][1], [arXiv][6])                                             |\n",
    "| Other claimed models (e.g., “ESPN BPI 68.9% accuracy”, “XGBoost + SHAP 78%”, “Transformer-based”, “real-timecalibration gains of 15–20pp”, etc.) | —                                   | **No supporting evidence found**                                                                              |\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "* **Verified performances**: GCN + RF (\\~71.5%), Osken & Onay (\\~76%), ESPN BPI (calibration and win rates 55–75%), KNN (\\~60%).\n",
    "* **Unsubstantiated claims** must be omitted unless citations are provided.\n",
    "\n",
    "If you'd like, I can help you draft an updated report or help locate sources for any of the unverified claims. Let me know!\n",
    "\n",
    "[1]: https://www.nature.com/articles/s41598-025-13657-1?utm_source=chatgpt.com \"Stacked ensemble model for NBA game outcome ...\"\n",
    "[2]: https://www.espn.com/blog/statsinfo/post/_/id/125994/bpi-and-strength-of-record-what-are-they-and-how-are-they-derived?utm_source=chatgpt.com \"Analytics Basketball Power Index (BPI), Strength of Record ...\"\n",
    "[3]: https://journals.plos.org/plosone/article/file?id=10.1371%2Fjournal.pone.0326326&type=printable&utm_source=chatgpt.com \"The application of artificial intelligence techniques in ...\"\n",
    "[4]: https://www.researchgate.net/publication/394518554_Stacked_ensemble_model_for_NBA_game_outcome_prediction_analysis?utm_source=chatgpt.com \"(PDF) Stacked ensemble model for NBA game outcome ...\"\n",
    "[5]: https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0307478&utm_source=chatgpt.com \"Integration of machine learning XGBoost and SHAP models ...\"\n",
    "[6]: https://arxiv.org/html/2410.21484v1?utm_source=chatgpt.com \"A Systematic Review of Machine Learning in Sports Betting\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile api/src/ml/config.py\n",
    "# FILE: api/src/ml/config.py (CORRECTED AND COMPLETE)\n",
    "from pathlib import Path\n",
    "from typing import Any, Union, Optional, Literal, Tuple\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ── Project root discovery ─────────────────────────────────────────────────────\n",
    "def find_project_root(name: str = \"nba_player_valuation_system\") -> Path:\n",
    "    \"\"\"Walk up from this file until a directory named `name` or containing .git is found.\"\"\"\n",
    "    try:\n",
    "        p = Path(__file__).resolve()\n",
    "    except NameError:\n",
    "        p = Path.cwd()\n",
    "    for parent in (p, *p.parents):\n",
    "        if parent.name == name or (parent / \".git\").is_dir():\n",
    "            return parent\n",
    "    return Path.cwd()\n",
    "\n",
    "# Core static paths\n",
    "PROJECT_ROOT: Path = Path(\"api\")\n",
    "DATA_DIR: Path = PROJECT_ROOT / \"src\" / \"ml\" / \"data\"\n",
    "AIRFLOW_DATA_DIR: Path = PROJECT_ROOT / \"src\" / \"airflow_project\" / \"data\"\n",
    "LOG_DIR: Path = PROJECT_ROOT / \"src\" / \"logs\"\n",
    "ARTIFACTS_DIR: Path = DATA_DIR / \"ml_artifacts\"\n",
    "REGISTRY_LOCAL_CACHE_DIR: Path = ARTIFACTS_DIR / \"registry_cache\"\n",
    "FINAL_ENGINEERED_DATASET_DIR: Path = AIRFLOW_DATA_DIR / \"merged_final_dataset\"\n",
    "FINAL_ML_DATASET_DIR: Path = DATA_DIR / \"final_ml_dataset\"\n",
    "MODEL_STORE_DIR: Path = DATA_DIR / \"model_store\"\n",
    "COLUMN_SCHEMA_PATH: Path = PROJECT_ROOT / \"src\" / \"ml\" / \"column_schema.yaml\"\n",
    "FEATURE_STORE_DIR: Path = DATA_DIR / \"feature_store\"\n",
    "FEATURE_SELECTION_DIR: Path = DATA_DIR / \"feature_selection\"\n",
    "MAX_CONTRACT_VALUES_CSV: Path = AIRFLOW_DATA_DIR / \"spotrac_contract_data\" / \"exported_csv\" / \"max_contract_values.csv\"\n",
    "\n",
    "# Environment and MLflow configuration\n",
    "ML_ENV: str = os.getenv(\"ML_ENV\", \"dev\")\n",
    "_DEFAULT_MLFLOW_TRACKING_URI = (ARTIFACTS_DIR / \"mlruns\").resolve().as_uri()\n",
    "_raw_mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\", _DEFAULT_MLFLOW_TRACKING_URI)\n",
    "\n",
    "def _canonicalize_tracking_uri(uri: str) -> str:\n",
    "    \"\"\"Normalize a user-provided tracking URI into something MLflow accepts.\"\"\"\n",
    "    from urllib.parse import urlparse\n",
    "    parsed = urlparse(uri)\n",
    "    if parsed.scheme in (\"http\", \"https\"):\n",
    "        return uri\n",
    "    if parsed.scheme == \"file\":\n",
    "        path_part = uri[len(\"file://\"):]\n",
    "        try:\n",
    "            p = Path(path_part)\n",
    "            return p.resolve().as_uri()\n",
    "        except Exception:\n",
    "            return uri\n",
    "    try:\n",
    "        p = Path(uri)\n",
    "        return p.resolve().as_uri()\n",
    "    except Exception:\n",
    "        return uri\n",
    "\n",
    "def _parse_families_env(raw: str) -> tuple[str, ...]:\n",
    "    \"\"\"Robustly parse MODEL_FAMILIES_SMOKE from either JSON or CSV.\"\"\"\n",
    "    s = (raw or \"\").strip()\n",
    "    out: list[str] = []\n",
    "    if not s:\n",
    "        return tuple()\n",
    "\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            arr = json.loads(s)\n",
    "            for x in arr:\n",
    "                t = str(x).strip().strip(\"'\\\"\")\n",
    "                if t and t not in out:\n",
    "                    out.append(t)\n",
    "            return tuple(out)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    s = s.strip(\"[]\")\n",
    "    for tok in s.split(\",\"):\n",
    "        t = tok.strip().strip(\"'\\\"[]\")\n",
    "        if t and t not in out:\n",
    "            out.append(t)\n",
    "    return tuple(out)\n",
    "\n",
    "# Final configurations\n",
    "MLFLOW_TRACKING_URI: str = _canonicalize_tracking_uri(_raw_mlflow_uri)\n",
    "MLFLOW_EXPERIMENT_NAME: str = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"nba_featurestore_smoke\")\n",
    "MODEL_ARTIFACTS_DIR: Path = Path(os.getenv(\"MODEL_ARTIFACTS_DIR\", str(ARTIFACTS_DIR)))\n",
    "FEATURE_STORE_DIR: Path = Path(os.getenv(\"FEATURE_STORE_DIR\", str(FEATURE_STORE_DIR)))\n",
    "FEATURESTORE_PREFERRED_STAGE: str = os.getenv(\"FEATURESTORE_PREFERRED_STAGE\", \"Production\")\n",
    "FEATURESTORE_AUTO_BOOTSTRAP: bool = os.getenv(\"FEATURESTORE_AUTO_BOOTSTRAP\", \"1\").lower() in (\"1\", \"true\", \"yes\")\n",
    "DEFAULT_FEATURESTORE_MODEL_FAMILY: str = os.getenv(\"FEATURESTORE_MODEL_FAMILY\", \"linear_ridge\")\n",
    "\n",
    "# Enhanced model families with stacking\n",
    "DEFAULT_MODEL_FAMILIES_SMOKE: tuple[str, ...] = _parse_families_env(\n",
    "    os.getenv(\"MODEL_FAMILIES_SMOKE\", \"linear_ridge,lasso,elasticnet,rf,xgb,lgbm,cat,stacking\")\n",
    ")\n",
    "\n",
    "# Stacking-specific configuration\n",
    "STACKING_DEFAULT_BASE_ESTIMATORS: tuple[str, ...] = _parse_families_env(\n",
    "    os.getenv(\"STACKING_BASE_ESTIMATORS\", \"linear_ridge,xgb,lgbm,cat\")\n",
    ")\n",
    "STACKING_DEFAULT_META_LEARNER: str = os.getenv(\"STACKING_META_LEARNER\", \"linear_ridge\")\n",
    "STACKING_DEFAULT_CV_FOLDS: int = int(os.getenv(\"STACKING_CV_FOLDS\", \"5\"))\n",
    "STACKING_DEFAULT_CV_STRATEGY: str = os.getenv(\"STACKING_CV_STRATEGY\", \"time_series\")\n",
    "STACKING_USE_PASSTHROUGH: bool = os.getenv(\"STACKING_USE_PASSTHROUGH\", \"false\").lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "# Utility functions\n",
    "def feature_store_namespace(model_family: str, target: str) -> str:\n",
    "    return f\"{model_family}_{target}\"\n",
    "\n",
    "SELECTED_METRIC: Literal[\"rmse\", \"mae\", \"r2\"] = os.getenv(\"SELECTED_METRIC\", \"mae\").lower()\n",
    "\n",
    "def metric_higher_is_better(metric: str) -> bool:\n",
    "    return metric.lower() in {\"r2\"}\n",
    "\n",
    "# Registry configuration\n",
    "USE_MODEL_REGISTRY: bool = os.getenv(\"USE_MODEL_REGISTRY\", \"1\").lower() in (\"1\",\"true\",\"yes\")\n",
    "REGISTRY_ALIAS_DEV = os.getenv(\"MLFLOW_ALIAS_DEV\", \"dev\")\n",
    "REGISTRY_ALIAS_STAGE = os.getenv(\"MLFLOW_ALIAS_STAGE\", \"stage\")\n",
    "REGISTRY_ALIAS_PROD = os.getenv(\"MLFLOW_ALIAS_PROD\", \"prod\")\n",
    "\n",
    "def registry_alias_for_env(env: Optional[str] = None) -> str:\n",
    "    e = _normalize_stage_env(env or ML_ENV)\n",
    "    return {\n",
    "        \"dev\": REGISTRY_ALIAS_DEV,\n",
    "        \"stage\": REGISTRY_ALIAS_STAGE,\n",
    "        \"prod\": REGISTRY_ALIAS_PROD,\n",
    "    }.get(e, REGISTRY_ALIAS_DEV)\n",
    "\n",
    "def registry_name_for_target(target: str) -> str:\n",
    "    default = f\"nba_{target}_regressor\"\n",
    "    return os.getenv(\"MODEL_REGISTRY_NAME\", default)\n",
    "\n",
    "# Stage profiles\n",
    "_STAGE_ALIASES: dict[str, str] = {\n",
    "    \"staging\": \"stage\",\n",
    "    \"production\": \"prod\",\n",
    "    \"development\": \"dev\",\n",
    "}\n",
    "\n",
    "def _normalize_stage_env(env: Optional[str] = None) -> str:\n",
    "    e = (env or ML_ENV).lower()\n",
    "    return _STAGE_ALIASES.get(e, e)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StageProfile:\n",
    "    name: Literal[\"dev\", \"stage\", \"prod\"]\n",
    "    registry_stage: Literal[\"Staging\", \"Production\"]\n",
    "    selected_metric: Literal[\"rmse\", \"mae\", \"r2\"] = SELECTED_METRIC\n",
    "    min_improvement: float = 0.0\n",
    "\n",
    "STAGE_PROFILES: dict[str, StageProfile] = {\n",
    "    \"dev\": StageProfile(\"dev\", \"Staging\", selected_metric=SELECTED_METRIC, min_improvement=0.0),\n",
    "    \"stage\": StageProfile(\"stage\", \"Staging\", selected_metric=SELECTED_METRIC, min_improvement=0.0),\n",
    "    \"prod\": StageProfile(\"prod\", \"Production\", selected_metric=SELECTED_METRIC, min_improvement=0.0),\n",
    "}\n",
    "\n",
    "# Bundle directories\n",
    "BUNDLE_ROOT: Path = ARTIFACTS_DIR / \"model_bundles\"\n",
    "FAMILY_BUNDLE_ROOT: Path = ARTIFACTS_DIR / \"family_bundles\"\n",
    "\n",
    "def family_bundle_dir_for(model_family: str, target: str, env: Optional[str] = None) -> Path:\n",
    "    canonical = _normalize_stage_env(env or ML_ENV)\n",
    "    return FAMILY_BUNDLE_ROOT / target / model_family / canonical\n",
    "\n",
    "def bundle_dir_for(target: str, env: Optional[str] = None) -> Path:\n",
    "    canonical = _normalize_stage_env(env or ML_ENV)\n",
    "    return BUNDLE_ROOT / target / canonical\n",
    "\n",
    "# Behavior switches\n",
    "AUTOCLEAN_FAMILY_ARTIFACTS: bool = os.getenv(\"AUTOCLEAN_FAMILY_ARTIFACTS\", \"1\").lower() in (\"1\", \"true\", \"yes\")\n",
    "PREDICT_USE_BUNDLE_FIRST: bool = os.getenv(\"PREDICT_USE_BUNDLE_FIRST\", \"1\").lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "def registry_stage_for_env(env: Optional[str] = None) -> str:\n",
    "    canonical = _normalize_stage_env(env)\n",
    "    return STAGE_PROFILES.get(canonical, STAGE_PROFILES[\"dev\"]).registry_stage\n",
    "\n",
    "# MISSING TRAINING CONFIG CLASS (ROOT CAUSE OF ERROR)\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"\n",
    "    Training configuration for any model family (sklearn/stacking/bayes_hier).\n",
    "    \"\"\"\n",
    "    model_family: str = \"linear_ridge\"\n",
    "    target: str = \"AAV\"\n",
    "    use_cap_pct_target: bool = False\n",
    "    max_train_rows: Optional[int] = None\n",
    "    n_splits: int = 4\n",
    "    n_trials: int = 20\n",
    "    random_state: int = 42\n",
    "    drop_columns_exact: list[str] = None\n",
    "    feature_exclude_prefixes: list[str] = None\n",
    "\n",
    "    # --- Bayesian-only knobs (new) ---\n",
    "    bayes_draws: int = int(os.getenv(\"BAYES_DRAWS\", \"1000\"))\n",
    "    bayes_tune: int = int(os.getenv(\"BAYES_TUNE\", \"1000\"))\n",
    "    bayes_target_accept: float = float(os.getenv(\"BAYES_TARGET_ACCEPT\", \"0.9\"))\n",
    "    bayes_chains: int = int(os.getenv(\"BAYES_CHAINS\", \"2\"))\n",
    "    bayes_cores: int = int(os.getenv(\"BAYES_CORES\", \"2\"))\n",
    "    # configurable grouping columns; default common pair\n",
    "    bayes_group_cols: tuple[str, ...] = tuple(\n",
    "        os.getenv(\"BAYES_GROUP_COLS\", \"position,Season\").split(\",\")\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.drop_columns_exact is None:\n",
    "            self.drop_columns_exact = []\n",
    "        if self.feature_exclude_prefixes is None:\n",
    "            self.feature_exclude_prefixes = []\n",
    "        # basic sanity\n",
    "        if self.bayes_draws < 100 or self.bayes_tune < 100:\n",
    "            print(\"[TrainingConfig] Warning: very small draws/tune may lead to unstable posteriors.\")\n",
    "\n",
    "@dataclass\n",
    "class DevTrainConfig:\n",
    "    \"\"\"Enhanced DevTrainConfig with stacking ensemble support.\"\"\"\n",
    "    stage: Literal[\"dev\", \"train\", \"prod\"] = \"dev\"\n",
    "\n",
    "    # Enhanced preprocessing\n",
    "    numerical_imputation: Literal[\"mean\", \"median\", \"iterative\"] = \"median\"\n",
    "    add_missing_indicators: bool = True\n",
    "    quantile_clipping: tuple[float, float] = (0.01, 0.99)\n",
    "    max_safe_rows: int = 200_000\n",
    "    apply_type_conversions: bool = True\n",
    "    drop_unexpected_columns: bool = True\n",
    "\n",
    "    # Feature scaling improvements\n",
    "    enable_robust_scaling: bool = True\n",
    "    enable_outlier_detection: bool = True\n",
    "    outlier_contamination: float = 0.1\n",
    "\n",
    "    # Feature selection\n",
    "    perm_threshold: float = 0.001\n",
    "    shap_threshold: float = 0.001\n",
    "    selection_mode: Literal[\"intersection\", \"union\"] = \"union\"\n",
    "    min_features: int = 10\n",
    "    max_features: Optional[int] = None\n",
    "    fallback_strategy: Literal[\"top_permutation\", \"top_shap\", \"all\"] = \"top_permutation\"\n",
    "    perm_n_repeats: int = 10\n",
    "    perm_max_samples: float | int | None = 0.5\n",
    "    perm_n_jobs: int = 2\n",
    "    shap_nsamples: int = 100\n",
    "    max_relative_regression: float = 0.05\n",
    "\n",
    "    # Model-specific convergence settings\n",
    "    linear_max_iter: int = 50000\n",
    "    linear_tol: float = 1e-6\n",
    "    enable_feature_selection_for_linear: bool = True\n",
    "\n",
    "    # Cross-validation improvements\n",
    "    cv_strategy: Literal[\"time_series\", \"group\", \"stratified\"] = \"time_series\"\n",
    "    cv_n_splits: int = 5\n",
    "    cv_test_size: float = 0.2\n",
    "\n",
    "    # Stacking ensemble configuration\n",
    "    stacking_base_estimators: tuple[str, ...] = STACKING_DEFAULT_BASE_ESTIMATORS\n",
    "    stacking_meta_learner: str = STACKING_DEFAULT_META_LEARNER\n",
    "    stacking_cv_folds: int = STACKING_DEFAULT_CV_FOLDS\n",
    "    stacking_cv_strategy: str = STACKING_DEFAULT_CV_STRATEGY\n",
    "    stacking_use_passthrough: bool = STACKING_USE_PASSTHROUGH\n",
    "    stacking_enable_base_tuning: bool = True\n",
    "    stacking_meta_tuning_trials: int = 20\n",
    "\n",
    "    def make_selection_kwargs(self) -> dict:\n",
    "        \"\"\"Build a dict that can be unpacked into SelectionConfig-like consumers.\"\"\"\n",
    "        return {\n",
    "            \"perm_n_repeats\": self.perm_n_repeats,\n",
    "            \"perm_max_samples\": self.perm_max_samples,\n",
    "            \"perm_n_jobs\": self.perm_n_jobs,\n",
    "            \"perm_threshold\": self.perm_threshold,\n",
    "            \"shap_nsamples\": self.shap_nsamples,\n",
    "            \"shap_threshold\": self.shap_threshold,\n",
    "            \"mode\": self.selection_mode,\n",
    "            \"min_features\": self.min_features,\n",
    "            \"max_features\": self.max_features,\n",
    "            \"fallback_strategy\": self.fallback_strategy,\n",
    "            \"max_relative_regression\": self.max_relative_regression,\n",
    "        }\n",
    "\n",
    "    def make_stacking_params(self) -> dict:\n",
    "        \"\"\"Build default stacking parameters from configuration.\"\"\"\n",
    "        return {\n",
    "            \"base_estimators\": list(self.stacking_base_estimators),\n",
    "            \"meta_learner\": self.stacking_meta_learner,\n",
    "            \"cv_folds\": self.stacking_cv_folds,\n",
    "            \"cv_strategy\": self.stacking_cv_strategy,\n",
    "            \"passthrough\": self.stacking_use_passthrough,\n",
    "            \"base_params\": self._get_default_base_params(),\n",
    "            \"meta_params\": self._get_default_meta_params()\n",
    "        }\n",
    "\n",
    "    def _get_default_base_params(self) -> dict:\n",
    "        \"\"\"Get default hyperparameters for base estimators.\"\"\"\n",
    "        defaults = {\n",
    "            \"linear_ridge\": {\"alpha\": 1.0},\n",
    "            \"lasso\": {\"alpha\": 0.01},\n",
    "            \"elasticnet\": {\"alpha\": 0.01, \"l1_ratio\": 0.5},\n",
    "            \"rf\": {\"n_estimators\": 300, \"max_depth\": 10},\n",
    "            \"xgb\": {\"n_estimators\": 300, \"max_depth\": 6, \"learning_rate\": 0.1},\n",
    "            \"lgbm\": {\"n_estimators\": 300, \"max_depth\": 6, \"learning_rate\": 0.1},\n",
    "            \"cat\": {\"iterations\": 300, \"depth\": 6, \"learning_rate\": 0.1}\n",
    "        }\n",
    "        return {family: params for family, params in defaults.items() \n",
    "                if family in self.stacking_base_estimators}\n",
    "\n",
    "    def _get_default_meta_params(self) -> dict:\n",
    "        \"\"\"Get default hyperparameters for meta-learner.\"\"\"\n",
    "        meta_defaults = {\n",
    "            \"linear_ridge\": {\"alpha\": 0.1},\n",
    "            \"lasso\": {\"alpha\": 0.01, \"max_iter\": 10000},\n",
    "            \"elasticnet\": {\"alpha\": 0.01, \"l1_ratio\": 0.5, \"max_iter\": 10000}\n",
    "        }\n",
    "        return meta_defaults.get(self.stacking_meta_learner, {})\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Enhanced validation with stacking checks.\"\"\"\n",
    "        if not (0 <= self.quantile_clipping[0] < self.quantile_clipping[1] <= 1):\n",
    "            raise ValueError(\"quantile_clipping must satisfy 0 <= low < high <=1\")\n",
    "        if self.max_safe_rows < 1_000:\n",
    "            raise ValueError(\"max_safe_rows must be sensible (>=1000)\")\n",
    "        if self.min_features < 1:\n",
    "            raise ValueError(\"min_features must be >=1\")\n",
    "        if self.perm_threshold < 0 or self.shap_threshold < 0:\n",
    "            raise ValueError(\"thresholds must be non-negative\")\n",
    "\n",
    "        # Stacking validation\n",
    "        if len(self.stacking_base_estimators) < 2:\n",
    "            raise ValueError(\"stacking_base_estimators must have at least 2 estimators\")\n",
    "        if self.stacking_cv_folds < 2:\n",
    "            raise ValueError(\"stacking_cv_folds must be >= 2\")\n",
    "        if self.stacking_cv_strategy not in (\"time_series\", \"kfold\"):\n",
    "            raise ValueError(\"stacking_cv_strategy must be 'time_series' or 'kfold'\")\n",
    "\n",
    "@dataclass\n",
    "class TuningConfig:\n",
    "    \"\"\"Enhanced tuning configuration with stacking ensemble support.\"\"\"\n",
    "    model_families: Tuple[str, ...] = DEFAULT_MODEL_FAMILIES_SMOKE\n",
    "    n_trials: int = 20\n",
    "    n_splits: int = 4\n",
    "    use_bayesian: bool = True\n",
    "\n",
    "    # Stacking-specific tuning configuration\n",
    "    stacking_n_trials: int = 50\n",
    "    stacking_enable_base_tuning: bool = False\n",
    "    stacking_base_trials_per_family: int = 10\n",
    "    stacking_meta_trials: int = 20\n",
    "    stacking_max_base_combinations: int = 10\n",
    "\n",
    "    def get_trials_for_family(self, model_family: str) -> int:\n",
    "        \"\"\"Get the appropriate number of trials for a given model family.\"\"\"\n",
    "        if model_family == \"stacking\":\n",
    "            return self.stacking_n_trials\n",
    "        return self.n_trials\n",
    "\n",
    "    def should_tune_family(self, model_family: str) -> bool:\n",
    "        \"\"\"Determine whether to tune a specific model family.\"\"\"\n",
    "        if not self.use_bayesian:\n",
    "            return False\n",
    "        if model_family == \"stacking\" and not self.stacking_enable_base_tuning:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "# CREATE THE MISSING DEFAULTS INSTANCE (ROOT CAUSE FIX)\n",
    "DEFAULT_DEV_TRAIN_CONFIG = DevTrainConfig()\n",
    "DEFAULT_TUNING_CONFIG = TuningConfig()\n",
    "DEFAULTS = TrainingConfig()  # This was the missing piece causing the NameError!\n",
    "\n",
    "# Stacking ensemble utilities\n",
    "def get_stacking_default_params(target: str = \"AAV\") -> dict:\n",
    "    \"\"\"Get default stacking parameters optimized for NBA player valuation.\"\"\"\n",
    "    return {\n",
    "        \"base_estimators\": list(STACKING_DEFAULT_BASE_ESTIMATORS),\n",
    "        \"meta_learner\": STACKING_DEFAULT_META_LEARNER,\n",
    "        \"cv_folds\": STACKING_DEFAULT_CV_FOLDS,\n",
    "        \"cv_strategy\": STACKING_DEFAULT_CV_STRATEGY,\n",
    "        \"passthrough\": STACKING_USE_PASSTHROUGH,\n",
    "        \"base_params\": {\n",
    "            \"linear_ridge\": {\"alpha\": 1.0},\n",
    "            \"xgb\": {\n",
    "                \"n_estimators\": 300,\n",
    "                \"max_depth\": 6,\n",
    "                \"learning_rate\": 0.1,\n",
    "                \"subsample\": 0.8,\n",
    "                \"colsample_bytree\": 0.8\n",
    "            },\n",
    "            \"lgbm\": {\n",
    "                \"n_estimators\": 300,\n",
    "                \"max_depth\": 6,\n",
    "                \"learning_rate\": 0.1,\n",
    "                \"subsample\": 0.8,\n",
    "                \"colsample_bytree\": 0.8\n",
    "            },\n",
    "            \"cat\": {\n",
    "                \"iterations\": 300,\n",
    "                \"depth\": 6,\n",
    "                \"learning_rate\": 0.1\n",
    "            }\n",
    "        },\n",
    "        \"meta_params\": {\"alpha\": 0.1}\n",
    "    }\n",
    "\n",
    "def is_stacking_family(model_family: str) -> bool:\n",
    "    \"\"\"Check if a model family is a stacking ensemble.\"\"\"\n",
    "    return model_family.lower() == \"stacking\"\n",
    "\n",
    "def get_stacking_dependencies(model_family: str) -> list[str]:\n",
    "    \"\"\"Get the base model dependencies for a stacking model.\"\"\"\n",
    "    if not is_stacking_family(model_family):\n",
    "        return []\n",
    "    return list(STACKING_DEFAULT_BASE_ESTIMATORS)\n",
    "\n",
    "def get_training_order(model_families: list[str]) -> list[str]:\n",
    "    \"\"\"Return model families in the correct training order. Stacking models should be trained after their base estimators.\"\"\"\n",
    "    stacking_families = [f for f in model_families if is_stacking_family(f)]\n",
    "    base_families = [f for f in model_families if not is_stacking_family(f)]\n",
    "    return base_families + stacking_families\n",
    "\n",
    "# MISSING HELPER FUNCTION (ANOTHER ROOT CAUSE)\n",
    "def get_master_parquet_path() -> Path:\n",
    "    \"\"\"\n",
    "    Get the path to the master dataset parquet file.\n",
    "    This function was referenced but not defined, causing another potential error.\n",
    "    \"\"\"\n",
    "    return FINAL_ENGINEERED_DATASET_DIR / \"final_merged_with_all.parquet\"\n",
    "\n",
    "# Debug function to validate all required components exist\n",
    "def validate_configuration():\n",
    "    \"\"\"Debug function to validate all configuration components are properly defined.\"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check required classes exist\n",
    "    try:\n",
    "        TrainingConfig()\n",
    "        print(\"✅ TrainingConfig class defined correctly\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"❌ TrainingConfig error: {e}\")\n",
    "\n",
    "    # Check DEFAULTS exists\n",
    "    try:\n",
    "        assert DEFAULTS is not None\n",
    "        print(\"✅ DEFAULTS instance defined correctly\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"❌ DEFAULTS error: {e}\")\n",
    "\n",
    "    # Check required functions exist\n",
    "    try:\n",
    "        path = get_master_parquet_path()\n",
    "        print(f\"✅ get_master_parquet_path() returns: {path}\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"❌ get_master_parquet_path() error: {e}\")\n",
    "\n",
    "    # Check stacking utilities\n",
    "    try:\n",
    "        params = get_stacking_default_params()\n",
    "        print(f\"✅ Stacking params generated: {len(params)} keys\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"❌ Stacking utilities error: {e}\")\n",
    "\n",
    "    if errors:\n",
    "        print(\"\\n=== CONFIGURATION ERRORS ===\")\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n✅ All configuration components validated successfully!\")\n",
    "        return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== CONFIGURATION DEBUG VALIDATION ===\")\n",
    "    validate_configuration()\n",
    "\n",
    "    print(\"\\nTesting stacking configuration:\")\n",
    "    config = DevTrainConfig()\n",
    "    stacking_params = config.make_stacking_params()\n",
    "    print(f\"Default stacking params: {stacking_params}\")\n",
    "\n",
    "    print(\"\\nTesting training order:\")\n",
    "    families = [\"linear_ridge\", \"xgb\", \"stacking\", \"lgbm\", \"cat\"]\n",
    "    training_order = get_training_order(families)\n",
    "    print(f\"Training order: {training_order}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c0466",
   "metadata": {},
   "source": [
    "# ensemble training for example:\n",
    "# api/src/ml/train.py\n",
    "from __future__ import annotations\n",
    "import json, time, hashlib\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow, mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import all required components\n",
    "from api.src.ml import config\n",
    "from api.src.ml.config import (\n",
    "    TrainingConfig, DEFAULTS, DevTrainConfig, DEFAULT_DEV_TRAIN_CONFIG,\n",
    "    get_master_parquet_path, get_stacking_default_params\n",
    ")\n",
    "from api.src.ml.models.models import make_estimator\n",
    "from api.src.ml.column_schema import load_schema_from_yaml, SchemaConfig\n",
    "from api.src.ml.features.feature_engineering import engineer_features\n",
    "from api.src.ml.preprocessing.preprocessor import fit_preprocessor, transform_preprocessor\n",
    "from api.src.ml.preprocessing.feature_store.feature_store import FeatureStore\n",
    "from api.src.ml.preprocessing.feature_store.spec_builder import FeatureSpec, select_model_features, build_feature_spec_from_schema_and_preprocessor\n",
    "\n",
    "from api.src.ml.preprocessing.feature_selection import propose_feature_spec\n",
    "from api.src.ml.ml_config import SelectionConfig\n",
    "from api.src.ml.models.tune import optimize\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import sklearn as _sklog\n",
    "\n",
    "# Set matplotlib backend for compatibility\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "plt.ion()  # Enable interactive mode if needed\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# ENHANCED MAIN TRAINING FUNCTION WITH BAYESIAN SUPPORT\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def train(cfg: TrainingConfig = DEFAULTS) -> Path:\n",
    "    \"\"\"\n",
    "    Enhanced training function with proper preprocessing, feature selection, and Bayesian support.\n",
    "    \"\"\"\n",
    "    print(f\"[train] Starting training with config: {cfg}\")\n",
    "    \n",
    "    # Step 1: Load master dataset\n",
    "    try:\n",
    "        p = get_master_parquet_path()\n",
    "        print(f\"[train] Loading data from: {p}\")\n",
    "        df = pd.read_parquet(p)\n",
    "        print(f\"[train] Loaded dataset: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Master parquet not found ({e}), trying alternative path...\")\n",
    "        alt_path = config.FINAL_ENGINEERED_DATASET_DIR / \"final_merged_with_all.parquet\"\n",
    "        if alt_path.exists():\n",
    "            df = pd.read_parquet(alt_path)\n",
    "            print(f\"[train] Loaded from alternative path: {df.shape}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Could not find dataset at {p} or {alt_path}\")\n",
    "\n",
    "    # Step 2: Apply feature engineering\n",
    "    try:\n",
    "        df, _ = engineer_features(df)\n",
    "        print(\"✓ Applied feature engineering\")\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Feature engineering failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 3: Choose target\n",
    "    target = \"AAV_PCT_CAP\" if cfg.use_cap_pct_target else cfg.target\n",
    "    print(f\"[train] Target: {target}\")\n",
    "\n",
    "    # Step 4: Clean and filter data\n",
    "    try:\n",
    "        # Drop exact columns\n",
    "        if cfg.drop_columns_exact:\n",
    "            df_clean = df.drop(columns=cfg.drop_columns_exact, errors=\"ignore\")\n",
    "            print(f\"[train] Dropped {len(cfg.drop_columns_exact)} exact columns\")\n",
    "        else:\n",
    "            df_clean = df.copy()\n",
    "\n",
    "        # Filter by prefix\n",
    "        if cfg.feature_exclude_prefixes:\n",
    "            exclude_cols = [c for c in df_clean.columns \n",
    "                          if any(c.startswith(prefix) for prefix in cfg.feature_exclude_prefixes)]\n",
    "            df_clean = df_clean.drop(columns=exclude_cols)\n",
    "            print(f\"[train] Dropped {len(exclude_cols)} prefix-filtered columns\")\n",
    "\n",
    "        # Limit rows if specified\n",
    "        if cfg.max_train_rows and len(df_clean) > cfg.max_train_rows:\n",
    "            df_clean = df_clean.head(cfg.max_train_rows)\n",
    "            print(f\"[train] Limited to {cfg.max_train_rows} rows\")\n",
    "\n",
    "        print(f\"[train] Clean dataset: {df_clean.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Data cleaning failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 5: Load schema and preprocessor\n",
    "    try:\n",
    "        schema = load_schema_from_yaml(config.COLUMN_SCHEMA_PATH)\n",
    "        print(\"✓ Loaded column schema\")\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Schema loading failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 6: Create train/test split for honest evaluation\n",
    "    try:\n",
    "        # Use Season-based split if available, otherwise random\n",
    "        if \"Season\" in df_clean.columns:\n",
    "            # Time series split: use latest seasons for test\n",
    "            seasons = sorted(df_clean[\"Season\"].unique())\n",
    "            if len(seasons) >= 2:\n",
    "                test_seasons = seasons[-1:]  # Latest season for test\n",
    "                train_df = df_clean[~df_clean[\"Season\"].isin(test_seasons)].copy()\n",
    "                test_df = df_clean[df_clean[\"Season\"].isin(test_seasons)].copy()\n",
    "                print(f\"[train] Time series split: train={len(train_df)}, test={len(test_df)}\")\n",
    "            else:\n",
    "                train_df, test_df = train_test_split(df_clean, test_size=0.2, random_state=cfg.random_state)\n",
    "                print(f\"[train] Random split: train={len(train_df)}, test={len(test_df)}\")\n",
    "        else:\n",
    "            train_df, test_df = train_test_split(df_clean, test_size=0.2, random_state=cfg.random_state)\n",
    "            print(f\"[train] Random split: train={len(train_df)}, test={len(test_df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Train/test split failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 7: Fit preprocessor on training data\n",
    "    try:\n",
    "        dev_cfg = DEFAULT_DEV_TRAIN_CONFIG\n",
    "        X_train_np, y_train, preprocessor = fit_preprocessor(\n",
    "            train_df,\n",
    "            schema=schema,\n",
    "            model_type=\"linear\",  # For initial preprocessing\n",
    "            numerical_imputation=dev_cfg.numerical_imputation,\n",
    "            debug=False,\n",
    "            quantiles=dev_cfg.quantile_clipping,\n",
    "            max_safe_rows=200000,\n",
    "            apply_type_conversions=True,\n",
    "            drop_unexpected_schema_columns=True,\n",
    "        )\n",
    "        print(f\"✓ Fitted preprocessor: {X_train_np.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Preprocessor fitting failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 8: Bayesian training branch (enhanced with MLflow logging and holdout eval)\n",
    "    if cfg.model_family == \"bayes_hier\":\n",
    "        # Build spec using all features (no selection for Bayes by default)\n",
    "        spec = build_feature_spec_from_schema_and_preprocessor(\n",
    "            df=train_df,  # use the training portion for selecting columns\n",
    "            target=target,\n",
    "            schema=schema,\n",
    "            preprocessor=preprocessor,\n",
    "            final_features=None,  # use all features flowing through preprocessor/spec\n",
    "            clip_bounds=None,\n",
    "        )\n",
    "        fs = FeatureStore(cfg.model_family, target)\n",
    "        fs.save_spec(spec, {\"rows\": int(len(df_clean))})\n",
    "        print(\"✓ Saved FeatureSpec for Bayesian model\")\n",
    "\n",
    "        # --- MLflow logging & holdout eval to match sklearn families ---\n",
    "        mlflow.set_tracking_uri(config.MLFLOW_TRACKING_URI)\n",
    "        mlflow.set_experiment(config.MLFLOW_EXPERIMENT_NAME)\n",
    "        run_name = f\"bayes_hier::{target}\"\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            # log hyperparams\n",
    "            mlflow.log_params({\n",
    "                \"model_family\": cfg.model_family,\n",
    "                \"target\": target,\n",
    "                \"bayes_draws\": cfg.bayes_draws,\n",
    "                \"bayes_tune\": cfg.bayes_tune,\n",
    "                \"bayes_target_accept\": cfg.bayes_target_accept,\n",
    "                \"bayes_chains\": cfg.bayes_chains,\n",
    "                \"bayes_cores\": cfg.bayes_cores,\n",
    "                \"bayes_group_cols\": \",\".join(cfg.bayes_group_cols or ()),\n",
    "            })\n",
    "\n",
    "            # train on the training split only (to enable honest holdout)\n",
    "            from api.src.ml.bayes_hier import train_bayesian, predict_bayesian\n",
    "            out_dir, idata = train_bayesian(\n",
    "                df=train_df.copy(),\n",
    "                spec=spec,\n",
    "                draws=cfg.bayes_draws,\n",
    "                tune=cfg.bayes_tune,\n",
    "                target_accept=cfg.bayes_target_accept,\n",
    "                chains=cfg.bayes_chains,\n",
    "                cores=cfg.bayes_cores,\n",
    "                group_cols=cfg.bayes_group_cols,\n",
    "                random_seed=cfg.random_state,\n",
    "                out_dir=(config.ARTIFACTS_DIR / f\"bayes_hier_{target}\")\n",
    "            )\n",
    "            print(f\"✓ Bayesian posterior saved → {out_dir}\")\n",
    "\n",
    "            # Evaluate on holdout test_df (posterior mean)\n",
    "            y_true = test_df[target].astype(float).values\n",
    "            y_pred = predict_bayesian(\n",
    "                df=test_df.copy(),\n",
    "                spec=spec,\n",
    "                artifact_dir=out_dir,\n",
    "                group_cols=cfg.bayes_group_cols,\n",
    "            ).values\n",
    "\n",
    "            rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            print(f\"Bayesian holdout: RMSE={rmse:.4f}  MAE={mae:.4f}  R2={r2:.4f}\")\n",
    "\n",
    "            mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "            # log key artifacts\n",
    "            mlflow.log_artifact(str(out_dir / \"posterior.nc\"))\n",
    "            mlflow.log_artifact(str(out_dir / \"feature_names.txt\"))\n",
    "            if (out_dir / \"config_groups.json\").exists():\n",
    "                mlflow.log_artifact(str(out_dir / \"config_groups.json\"))\n",
    "\n",
    "            # Return the artifact path to match other families' behavior\n",
    "            return out_dir / \"posterior.nc\"\n",
    "    \n",
    "    # Step 9: For sklearn models, run feature selection\n",
    "    try:\n",
    "        # Create selection config\n",
    "        selection_cfg = SelectionConfig(\n",
    "            perm_n_repeats=10,\n",
    "            perm_max_samples=0.5,\n",
    "            perm_n_jobs=2,\n",
    "            perm_threshold=0.001,\n",
    "            shap_nsamples=100,\n",
    "            shap_threshold=0.001,\n",
    "            mode=\"union\",\n",
    "            min_features=10,\n",
    "            max_features=None,\n",
    "            fallback_strategy=\"top_permutation\",\n",
    "            max_relative_regression=0.05,\n",
    "        )\n",
    "\n",
    "        # Run feature selection on training data\n",
    "        spec = propose_feature_spec(\n",
    "            df=train_df,\n",
    "            target=target,\n",
    "            schema=schema,\n",
    "            preprocessor=preprocessor,\n",
    "            selection_config=selection_cfg,\n",
    "        )\n",
    "        print(f\"✓ Feature selection: {len(spec.final_features)} features selected\")\n",
    "\n",
    "        # Save spec to feature store\n",
    "        fs = FeatureStore(cfg.model_family, target)\n",
    "        fs.save_spec(spec, {\"rows\": int(len(df_clean))})\n",
    "        print(\"✓ Saved FeatureSpec to feature store\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Feature selection failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 10: Run optimization\n",
    "    try:\n",
    "        # Special handling for stacking models\n",
    "        if config.is_stacking_family(cfg.model_family):\n",
    "            print(f\"[train] Training stacking ensemble: {cfg.model_family}\")\n",
    "            stacking_params = get_stacking_default_params(target)\n",
    "            print(f\"[train] Using stacking params: {list(stacking_params.keys())}\")\n",
    "        \n",
    "        # Run optimization on full clean dataset\n",
    "        pipe, best_params, rmse = optimize(\n",
    "            df=df_clean,\n",
    "            feature_spec=spec,\n",
    "            model_family=cfg.model_family,\n",
    "            n_splits=cfg.n_splits,\n",
    "            n_trials=cfg.n_trials,\n",
    "            random_state=cfg.random_state,\n",
    "            experiment_name=config.MLFLOW_EXPERIMENT_NAME,\n",
    "        )\n",
    "        print(f\"✓ Optimization completed: RMSE={rmse:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[train] Optimization failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Step 11: Save model artifacts\n",
    "    try:\n",
    "        out_dir = config.ARTIFACTS_DIR / f\"{cfg.model_family}_{target}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_file = out_dir / \"model.joblib\"\n",
    "        joblib.dump(pipe, out_file)\n",
    "        print(f\"Saved model → {out_file} (CV RMSE ≈ {rmse:,.4f})\")\n",
    "        \n",
    "        # Save additional metadata for stacking models\n",
    "        if config.is_stacking_family(cfg.model_family):\n",
    "            meta_file = out_dir / \"stacking_meta.json\"\n",
    "            try:\n",
    "                stacking_model = pipe.named_steps['model']\n",
    "                from api.src.ml.models.models import get_stacking_feature_importance\n",
    "                importance_info = get_stacking_feature_importance(stacking_model)\n",
    "                \n",
    "                meta_data = {\n",
    "                    \"base_estimators\": importance_info.get(\"base_estimators\", []),\n",
    "                    \"base_weights\": importance_info.get(\"base_predictions_weight\", {}),\n",
    "                    \"meta_learner\": importance_info.get(\"meta_learner\", \"\"),\n",
    "                    \"cv_rmse\": float(rmse),\n",
    "                    \"n_features\": len(spec.final_features),\n",
    "                }\n",
    "                meta_file.write_text(json.dumps(meta_data, indent=2))\n",
    "                print(f\"✓ Saved stacking metadata → {meta_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[train] Stacking metadata save failed: {e}\")\n",
    "\n",
    "        return out_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[train] Model saving failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the training function\n",
    "    cfg = TrainingConfig(\n",
    "        model_family=\"bayes_hier\",\n",
    "        target=\"AAV\",\n",
    "        bayes_draws=300,  # quick smoke test\n",
    "        bayes_tune=300,\n",
    "        bayes_group_cols=(\"position\", \"Season\"),\n",
    "    )\n",
    "    result_path = train(cfg)\n",
    "    print(f\"Training completed: {result_path}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afd0d8",
   "metadata": {},
   "source": [
    "# Bayesian Hierarchichal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85997802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENHANCED BAYESIAN REAL-DATA SMOKE ===\n",
      "[env] python: 3.10.12 (main, Aug 15 2025, 14:32:43) [GCC 11.4.0]\n",
      "[env] pymc: 5.25.1\n",
      "[env] arviz: 0.22.0\n",
      "[env] numpy: 1.26.4\n",
      "[env] sklearn: 1.5.2\n",
      "[env] g++ available: True\n",
      "✅ TrainingConfig class defined correctly\n",
      "✅ DEFAULTS instance defined correctly\n",
      "✅ get_master_parquet_path() returns: api/src/airflow_project/data/merged_final_dataset/final_merged_with_all.parquet\n",
      "✅ Stacking params generated: 7 keys\n",
      "\n",
      "✅ All configuration components validated successfully!\n",
      "✓ Configuration validated\n",
      "✓ Real dataset exists → api/src/airflow_project/data/merged_final_dataset/final_merged_with_all.parquet\n",
      "[smoke] Loaded dataset: (1955, 346)\n",
      "=== DATA VALIDATION BEFORE TRAINING ===\n",
      "Target 'AAV' statistics:\n",
      "count    1.955000e+03\n",
      "mean     5.838700e+06\n",
      "std      8.983560e+06\n",
      "min      3.197000e+03\n",
      "25%      8.983100e+05\n",
      "50%      2.328652e+06\n",
      "75%      6.525322e+06\n",
      "max      5.707873e+07\n",
      "Name: AAV, dtype: float64\n",
      "⚠️ Issues detected:\n",
      "  too_many_features: High feature count: 296 numeric columns\n",
      "[smoke] using cfg: TrainingConfig(model_family='bayes_hier', target='AAV', use_cap_pct_target=False, max_train_rows=3000, n_splits=4, n_trials=20, random_state=42, drop_columns_exact=[], feature_exclude_prefixes=[], bayes_draws=1000, bayes_tune=1000, bayes_target_accept=0.9, bayes_chains=2, bayes_cores=2, bayes_group_cols=('POSITION', 'SEASON', 'PLAYER_ID', 'TEAM_ID'))\n",
      "[smoke] Running Bayesian training...\n",
      "[train] Starting training with config: TrainingConfig(model_family='bayes_hier', target='AAV', use_cap_pct_target=False, max_train_rows=3000, n_splits=4, n_trials=20, random_state=42, drop_columns_exact=[], feature_exclude_prefixes=[], bayes_draws=1000, bayes_tune=1000, bayes_target_accept=0.9, bayes_chains=2, bayes_cores=2, bayes_group_cols=('POSITION', 'SEASON', 'PLAYER_ID', 'TEAM_ID'))\n",
      "[train] Loading data from: api/src/airflow_project/data/merged_final_dataset/final_merged_with_all.parquet\n",
      "[train] Loaded dataset: (1955, 346)\n",
      "[debug] added time features: ['season_start_year']\n",
      "[debug] added market tier features: ['market_tier']\n",
      "[load_max_contract_values] Using detected delimiter: ','\n",
      "[add_max_contract_salary] merge status:\n",
      " _merge_maxsalary\n",
      "both          1955\n",
      "left_only        0\n",
      "right_only       0\n",
      "Name: count, dtype: int64\n",
      "[debug] added max-contract features: ['AAV_PCT_OF_MAX', 'MAXIMUM_CONTRACT_SALARY', 'MAX_PERCENTAGE_OF_CAP', 'max_pct_source']\n",
      "[debug] added salary cap normalization features: ['AAV_PCT_CAP']\n",
      "[debug] experience_bucket counts:\n",
      "experience_bucket\n",
      "6-9      616\n",
      "3-5      484\n",
      "10-14    465\n",
      "15+      212\n",
      "1-2      178\n",
      "0          0\n",
      "Name: count, dtype: int64\n",
      "[debug] added experience bucket: ['experience_bucket'] with order ['0', '1-2', '3-5', '6-9', '10-14', '15+']\n",
      "[debug] added team cap space features: ['team_total_commitment', 'team_cap_space', 'pct_cap_used', 'is_over_cap', 'pushes_into_tax', 'pct_to_tax']\n",
      "[debug] added cap space bins/tiers\n",
      "[debug] added rolling features: ['WS_rollmean_3', 'PTS_PER_36_rollmean_3', 'WS_rollslope_3', 'PTS_PER_36_rollslope_3']\n",
      "[debug] added portability features: ['portability_score']\n",
      "[debug] added contract year flag: ['is_contract_year']\n",
      "===============missingness before injury reliability features\n",
      "         reason  count\n",
      "0   valid_stint   1232\n",
      "1  both_missing    723\n",
      "[post-injury-debug] both_missing count=723, zeros assigned=0\n",
      "[post-injury-debug][ERROR] 233 valid_stint rows have inconsistent TOTAL_DAYS_INJURED (expected end-start). Sample:\n",
      "     INJURY_START_DATE INJURY_END_DATE  TOTAL_DAYS_INJURED\n",
      "14          2015-12-12      2016-02-05                13.0\n",
      "64          2015-11-27      2016-04-17                43.0\n",
      "67          2015-10-28      2016-01-25                53.0\n",
      "30          2015-11-01      2016-01-18                18.0\n",
      "1372        2024-01-05      2024-03-25                 3.0\n",
      "===============missingness after injury reliability features\n",
      "         reason  count\n",
      "0   valid_stint   1232\n",
      "1  both_missing    723\n",
      "     INJURY_START_DATE INJURY_END_DATE  TOTAL_DAYS_INJURED\n",
      "201         2016-11-26      2016-12-07                11.0\n",
      "488         2018-12-22      2019-01-27                36.0\n",
      "883         2022-02-20      2022-03-24                32.0\n",
      "1675               NaT             NaT                 NaN\n",
      "234                NaT             NaT                 NaN\n",
      "416                NaT             NaT                 NaN\n",
      "617                NaT             NaT                 NaN\n",
      "483                NaT             NaT                 NaN\n",
      "14          2015-12-12      2016-02-05                13.0\n",
      "18                 NaT             NaT                 NaN\n",
      "Smoke test OK - Engineered features:\n",
      "  numerical: ['AAV_PCT_OF_MAX', 'MAXIMUM_CONTRACT_SALARY', 'MAX_PERCENTAGE_OF_CAP', 'AAV_PCT_CAP', 'team_total_commitment', 'team_cap_space', 'pct_cap_used', 'is_over_cap', 'pushes_into_tax', 'pct_to_tax', 'WS_rollmean_3', 'PTS_PER_36_rollmean_3', 'WS_rollslope_3', 'PTS_PER_36_rollslope_3', 'portability_score']\n",
      "  ordinal: ['experience_bucket', 'cap_space_bin']\n",
      "  nominal: ['market_tier', 'cap_space_tier', 'is_contract_year']\n",
      "  time: ['season_start_year']\n",
      "✓ Applied feature engineering\n",
      "[train] Target: AAV\n",
      "[train] Clean dataset: (1955, 369)\n",
      "[load_schema] top-level keys: ['id', 'ordinal', 'nominal', 'numerical', 'general', 'scoring', 'advanced', 'playmaking', 'rebounding', 'defense', 'usage', 'rankings', 'team', 'efficiency', 'hustle_boxouts', 'offensive_play_types', 'defensive_play_types', 'usage_related', 'miscellaneous', 'target']\n",
      "[load_schema] YAML content:\n",
      "id:\n",
      "- PLAYER_ID\n",
      "- TEAM_ID\n",
      "ordinal:\n",
      "- SEASON\n",
      "- season_start_year\n",
      "- experience_bucket\n",
      "- AGE\n",
      "nominal:\n",
      "- POSITION\n",
      "- SEASON_TYPE\n",
      "- market_tier\n",
      "- cap_space_tier\n",
      "numerical:\n",
      "- GP\n",
      "- GS\n",
      "- MP\n",
      "- PLAYER_POSS\n",
      "- TM_FGA\n",
      "- TM_FG\n",
      "- TM_TRB\n",
      "- TM_TOV\n",
      "- TM_ORB\n",
      "- TM_MP\n",
      "- TM_FTA\n",
      "- TM_DRB\n",
      "- TM_AST\n",
      "- FG\n",
      "- FGA\n",
      "- FG%\n",
      "- 3P\n",
      "- 3PA\n",
      "- 3P%\n",
      "- 2P\n",
      "- 2PA\n",
      "- 2P%\n",
      "- FT\n",
      "- FTA\n",
      "- FT%\n",
      "- FTR\n",
      "- EFG%\n",
      "- TS%\n",
      "- USG%\n",
      "- TRUE_USAGE%\n",
      "- TURNOVER_USAGE%\n",
      "- PLAYMAKING_USAGE%\n",
      "- SCORING_USAGE%\n",
      "- PER\n",
      "- BPM\n",
      "- OBPM\n",
      "- DBPM\n",
      "- VORP\n",
      "- OWS\n",
      "- DWS\n",
      "- WS\n",
      "- WS/48\n",
      "- OFFENSIVE_LOAD%\n",
      "- WS_rollmean_3\n",
      "- portability_score\n",
      "- AST_RANK\n",
      "- BLK_RANK\n",
      "- BLKA_RANK\n",
      "- OREB_RANK\n",
      "- REB_RANK\n",
      "- PTS_RANK\n",
      "- PLUS_MINUS_RANK\n",
      "- FTA_RANK\n",
      "- FT_PCT_RANK\n",
      "- FG_PCT_RANK\n",
      "- FGM_RANK\n",
      "- W_RANK\n",
      "- L_RANK\n",
      "- W_PCT_RANK\n",
      "- MIN_RANK\n",
      "- TD3_RANK\n",
      "- DD2_RANK\n",
      "- WINS\n",
      "- LOSSES\n",
      "- W_PCT\n",
      "- W\n",
      "- L\n",
      "- 3PAR\n",
      "- AST\n",
      "- AST%\n",
      "- BLK\n",
      "- BLK%\n",
      "- BLKA\n",
      "- BOX_OUTS\n",
      "- BOX_OUT_PLAYER_REBS\n",
      "- BOX_OUT_PLAYER_TEAM_REBS\n",
      "- BPM_BBREF\n",
      "- CHARGES_DRAWN\n",
      "- CONTESTED_SHOTS\n",
      "- CONTESTED_SHOTS_2PT\n",
      "- CONTESTED_SHOTS_3PT\n",
      "- DD2\n",
      "- DEFLECTIONS\n",
      "- DEF_BOXOUTS\n",
      "- DEF_LOOSE_BALLS_RECOVERED\n",
      "- DRB\n",
      "- DRB%\n",
      "- DREB\n",
      "- DREB_RANK\n",
      "- DWS_BBREF\n",
      "- D_FG_PCT\n",
      "- E_AST_RATIO\n",
      "- E_AST_RATIO_RANK\n",
      "- E_DEF_RATING\n",
      "- E_DEF_RATING_RANK\n",
      "- E_DREB_PCT\n",
      "- E_DREB_PCT_RANK\n",
      "- E_NET_RATING\n",
      "- E_NET_RATING_RANK\n",
      "- E_OFF_RATING\n",
      "- E_OFF_RATING_RANK\n",
      "- E_OREB_PCT\n",
      "- E_OREB_PCT_RANK\n",
      "- E_PACE\n",
      "- E_PACE_RANK\n",
      "- E_REB_PCT\n",
      "- E_REB_PCT_RANK\n",
      "- E_TOV_PCT\n",
      "- E_TOV_PCT_RANK\n",
      "- E_USG_PCT\n",
      "- E_USG_PCT_RANK\n",
      "- FG3A\n",
      "- FG3A_RANK\n",
      "- FG3M\n",
      "- FG3M_RANK\n",
      "- FG3_PCT\n",
      "- FG3_PCT_RANK\n",
      "- FGA_RANK\n",
      "- FGM\n",
      "- FG_PCT\n",
      "- FTM\n",
      "- FTM_RANK\n",
      "- FT_PCT\n",
      "- G\n",
      "- GP_RANK\n",
      "- MIN\n",
      "- OFF_BOXOUTS\n",
      "- OFF_LOOSE_BALLS_RECOVERED\n",
      "- ORB\n",
      "- ORB%\n",
      "- OREB\n",
      "- PCT_BOX_OUTS_DEF\n",
      "- PCT_BOX_OUTS_OFF\n",
      "- PCT_BOX_OUTS_REB\n",
      "- PCT_BOX_OUTS_TEAM_REB\n",
      "- PCT_LOOSE_BALLS_RECOVERED_DEF\n",
      "- PCT_LOOSE_BALLS_RECOVERED_OFF\n",
      "- PF\n",
      "- PFD\n",
      "- PFD_RANK\n",
      "- PF_RANK\n",
      "- PLUS_MINUS\n",
      "- PTS\n",
      "- REB\n",
      "- SCREEN_ASSISTS\n",
      "- SCREEN_AST_PTS\n",
      "- STL\n",
      "- STL%\n",
      "- STL_RANK\n",
      "- TD3\n",
      "- TEAM_COUNT\n",
      "- TEAM_POSS\n",
      "- TOTAL_DAYS_INJURED\n",
      "- major_injury_14d_flag\n",
      "- major_injury_30d_flag\n",
      "- TOV\n",
      "- TOV%\n",
      "- TOV_RANK\n",
      "- TRB\n",
      "- TRB%\n",
      "- TRB%_BBREF\n",
      "- TRB_PER_36\n",
      "- VORP_BBREF\n",
      "- LOOSE_BALLS_RECOVERED\n",
      "- E_OFF_RATING_RANK\n",
      "- E_DEF_RATING_RANK\n",
      "- E_NET_RATING_RANK\n",
      "- E_AST_RATIO_RANK\n",
      "- E_OREB_PCT_RANK\n",
      "- E_DREB_PCT_RANK\n",
      "- E_REB_PCT_RANK\n",
      "- E_TOV_PCT_RANK\n",
      "- E_USG_PCT_RANK\n",
      "- E_PACE_RANK\n",
      "- L_RANK\n",
      "- OFF_EFG_PCT_CUT\n",
      "- OFF_EFG_PCT_HANDOFF\n",
      "- OFF_EFG_PCT_ISOLATION\n",
      "- OFF_EFG_PCT_MISC\n",
      "- OFF_EFG_PCT_OFFREBOUND\n",
      "- OFF_EFG_PCT_OFFSCREEN\n",
      "- OFF_EFG_PCT_PRBALLHANDLER\n",
      "- OFF_EFG_PCT_PRROLLMAN\n",
      "- OFF_EFG_PCT_POSTUP\n",
      "- OFF_EFG_PCT_SPOTUP\n",
      "- OFF_EFG_PCT_TRANSITION\n",
      "- OFF_FG_PCT_CUT\n",
      "- OFF_FG_PCT_HANDOFF\n",
      "- OFF_FG_PCT_ISOLATION\n",
      "- OFF_FG_PCT_MISC\n",
      "- OFF_FG_PCT_OFFREBOUND\n",
      "- OFF_FG_PCT_OFFSCREEN\n",
      "- OFF_FG_PCT_PRBALLHANDLER\n",
      "- OFF_FG_PCT_PRROLLMAN\n",
      "- OFF_FG_PCT_POSTUP\n",
      "- OFF_FG_PCT_SPOTUP\n",
      "- OFF_FG_PCT_TRANSITION\n",
      "- OFF_FT_POSS_PCT_CUT\n",
      "- OFF_FT_POSS_PCT_HANDOFF\n",
      "- OFF_FT_POSS_PCT_ISOLATION\n",
      "- OFF_FT_POSS_PCT_MISC\n",
      "- OFF_FT_POSS_PCT_OFFREBOUND\n",
      "- OFF_FT_POSS_PCT_OFFSCREEN\n",
      "- OFF_FT_POSS_PCT_PRBALLHANDLER\n",
      "- OFF_FT_POSS_PCT_PRROLLMAN\n",
      "- OFF_FT_POSS_PCT_POSTUP\n",
      "- OFF_FT_POSS_PCT_SPOTUP\n",
      "- OFF_FT_POSS_PCT_TRANSITION\n",
      "- OFF_POSS_CUT\n",
      "- OFF_POSS_HANDOFF\n",
      "- OFF_POSS_ISOLATION\n",
      "- OFF_POSS_MISC\n",
      "- OFF_POSS_OFFREBOUND\n",
      "- OFF_POSS_OFFSCREEN\n",
      "- OFF_POSS_PRBALLHANDLER\n",
      "- OFF_POSS_PRROLLMAN\n",
      "- OFF_POSS_POSTUP\n",
      "- OFF_POSS_SPOTUP\n",
      "- OFF_POSS_TRANSITION\n",
      "- OFF_PPP_CUT\n",
      "- OFF_PPP_HANDOFF\n",
      "- OFF_PPP_ISOLATION\n",
      "- OFF_PPP_MISC\n",
      "- OFF_PPP_OFFREBOUND\n",
      "- OFF_PPP_OFFSCREEN\n",
      "- OFF_PPP_PRBALLHANDLER\n",
      "- OFF_PPP_PRROLLMAN\n",
      "- OFF_PPP_POSTUP\n",
      "- OFF_PPP_SPOTUP\n",
      "- OFF_PPP_TRANSITION\n",
      "- DEF_EFG_PCT_HANDOFF\n",
      "- DEF_EFG_PCT_ISOLATION\n",
      "- DEF_EFG_PCT_OFFSCREEN\n",
      "- DEF_EFG_PCT_PRBALLHANDLER\n",
      "- DEF_EFG_PCT_PRROLLMAN\n",
      "- DEF_EFG_PCT_POSTUP\n",
      "- DEF_EFG_PCT_SPOTUP\n",
      "- DEF_FG_PCT_HANDOFF\n",
      "- DEF_FG_PCT_ISOLATION\n",
      "- DEF_FG_PCT_OFFSCREEN\n",
      "- DEF_FG_PCT_PRBALLHANDLER\n",
      "- DEF_FG_PCT_PRROLLMAN\n",
      "- DEF_FG_PCT_POSTUP\n",
      "- DEF_FG_PCT_SPOTUP\n",
      "- DEF_FT_POSS_PCT_HANDOFF\n",
      "- DEF_FT_POSS_PCT_ISOLATION\n",
      "- DEF_FT_POSS_PCT_OFFSCREEN\n",
      "- DEF_FT_POSS_PCT_PRBALLHANDLER\n",
      "- DEF_FT_POSS_PCT_PRROLLMAN\n",
      "- DEF_FT_POSS_PCT_POSTUP\n",
      "- DEF_FT_POSS_PCT_SPOTUP\n",
      "- DEF_POSS_HANDOFF\n",
      "- DEF_POSS_ISOLATION\n",
      "- DEF_POSS_OFFSCREEN\n",
      "- DEF_POSS_PRBALLHANDLER\n",
      "- DEF_POSS_PRROLLMAN\n",
      "- DEF_POSS_POSTUP\n",
      "- DEF_POSS_SPOTUP\n",
      "- DEF_PPP_HANDOFF\n",
      "- DEF_PPP_ISOLATION\n",
      "- DEF_PPP_OFFSCREEN\n",
      "- DEF_PPP_PRBALLHANDLER\n",
      "- DEF_PPP_PRROLLMAN\n",
      "- DEF_PPP_POSTUP\n",
      "- DEF_PPP_SPOTUP\n",
      "general:\n",
      "- GP\n",
      "- GS\n",
      "- MP\n",
      "- G\n",
      "- TEAM_COUNT\n",
      "- TEAM_POSS\n",
      "- PLAYER_POSS\n",
      "scoring:\n",
      "- PTS\n",
      "- FG\n",
      "- FGA\n",
      "- FG%\n",
      "- 2P\n",
      "- 2PA\n",
      "- 2P%\n",
      "- 3P\n",
      "- 3PA\n",
      "- 3P%\n",
      "- FT\n",
      "- FTA\n",
      "- FT%\n",
      "- EFG%\n",
      "- TS%\n",
      "advanced:\n",
      "- VORP\n",
      "- WS\n",
      "- OWS\n",
      "- DWS\n",
      "- WS/48\n",
      "- BPM\n",
      "- OBPM\n",
      "- DBPM\n",
      "- PER\n",
      "- VORP_BBREF\n",
      "- WS_rollmean_3\n",
      "- OFF_EFG_PCT_CUT\n",
      "- OFF_EFG_PCT_HANDOFF\n",
      "- OFF_EFG_PCT_ISOLATION\n",
      "- OFF_EFG_PCT_MISC\n",
      "- OFF_EFG_PCT_OFFREBOUND\n",
      "- OFF_EFG_PCT_OFFSCREEN\n",
      "- OFF_EFG_PCT_PRBALLHANDLER\n",
      "- OFF_EFG_PCT_PRROLLMAN\n",
      "- OFF_EFG_PCT_POSTUP\n",
      "- OFF_EFG_PCT_SPOTUP\n",
      "- OFF_EFG_PCT_TRANSITION\n",
      "- OFF_FG_PCT_CUT\n",
      "- OFF_FG_PCT_HANDOFF\n",
      "- OFF_FG_PCT_ISOLATION\n",
      "- OFF_FG_PCT_MISC\n",
      "- OFF_FG_PCT_OFFREBOUND\n",
      "- OFF_FG_PCT_OFFSCREEN\n",
      "- OFF_FG_PCT_PRBALLHANDLER\n",
      "- OFF_FG_PCT_PRROLLMAN\n",
      "- OFF_FG_PCT_POSTUP\n",
      "- OFF_FG_PCT_SPOTUP\n",
      "- OFF_FG_PCT_TRANSITION\n",
      "playmaking:\n",
      "- AST\n",
      "- TOV\n",
      "- AST%\n",
      "- TOV%\n",
      "- SCREEN_ASSISTS\n",
      "- SCREEN_AST_PTS\n",
      "- E_AST_RATIO\n",
      "- E_AST_RATIO_RANK\n",
      "- PCT_BOX_OUTS_OFF\n",
      "- PCT_LOOSE_BALLS_RECOVERED_OFF\n",
      "rebounding:\n",
      "- TRB\n",
      "- DRB\n",
      "- ORB\n",
      "- TRB%\n",
      "- ORB%\n",
      "- DRB%\n",
      "- TRB_PER_36\n",
      "- REB\n",
      "- DREB\n",
      "- OREB\n",
      "- DRB\n",
      "- DREB_RANK\n",
      "- OREB_RANK\n",
      "- PCT_BOX_OUTS_REB\n",
      "- PCT_BOX_OUTS_TEAM_REB\n",
      "defense:\n",
      "- STL\n",
      "- BLK\n",
      "- PF\n",
      "- STL%\n",
      "- BLK%\n",
      "- PLUS_MINUS\n",
      "- PLUS_MINUS_RANK\n",
      "- CONTESTED_SHOTS\n",
      "- CONTESTED_SHOTS_2PT\n",
      "- CONTESTED_SHOTS_3PT\n",
      "- DEF_BOXOUTS\n",
      "- DEF_LOOSE_BALLS_RECOVERED\n",
      "- PCT_BOX_OUTS_DEF\n",
      "- PCT_LOOSE_BALLS_RECOVERED_DEF\n",
      "usage:\n",
      "- USG%\n",
      "- TRUE_USAGE%\n",
      "- TURNOVER_USAGE%\n",
      "- PLAYMAKING_USAGE%\n",
      "- SCORING_USAGE%\n",
      "- OFFENSIVE_LOAD%\n",
      "rankings:\n",
      "- AST_RANK\n",
      "- BLK_RANK\n",
      "- BLKA_RANK\n",
      "- OREB_RANK\n",
      "- REB_RANK\n",
      "- PTS_RANK\n",
      "- FTA_RANK\n",
      "- FT_PCT_RANK\n",
      "- FG_PCT_RANK\n",
      "- FGM_RANK\n",
      "- W_RANK\n",
      "- L_RANK\n",
      "- W_PCT_RANK\n",
      "- MIN_RANK\n",
      "- STL_RANK\n",
      "- GP_RANK\n",
      "- E_OFF_RATING_RANK\n",
      "- E_DEF_RATING_RANK\n",
      "- E_NET_RATING_RANK\n",
      "- E_AST_RATIO_RANK\n",
      "- E_OREB_PCT_RANK\n",
      "- E_DREB_PCT_RANK\n",
      "- E_REB_PCT_RANK\n",
      "- E_TOV_PCT_RANK\n",
      "- E_USG_PCT_RANK\n",
      "- E_PACE_RANK\n",
      "- FG3A_RANK\n",
      "- FG3M_RANK\n",
      "- FG3_PCT_RANK\n",
      "- FTM_RANK\n",
      "- GP_RANK\n",
      "team:\n",
      "- WINS\n",
      "- LOSSES\n",
      "- W_PCT\n",
      "- W\n",
      "- L\n",
      "- TEAM_POSS\n",
      "- TEAM_COUNT\n",
      "efficiency:\n",
      "- MIN\n",
      "- OFF_BOXOUTS\n",
      "hustle_boxouts:\n",
      "- BOX_OUTS\n",
      "- BOX_OUT_PLAYER_REBS\n",
      "- BOX_OUT_PLAYER_TEAM_REBS\n",
      "- CHARGES_DRAWN\n",
      "- LOOSE_BALLS_RECOVERED\n",
      "- DEF_BOXOUTS\n",
      "- OFF_BOXOUTS\n",
      "- OFF_LOOSE_BALLS_RECOVERED\n",
      "- DEF_LOOSE_BALLS_RECOVERED\n",
      "offensive_play_types:\n",
      "- OFF_POSS_CUT\n",
      "- OFF_POSS_HANDOFF\n",
      "- OFF_POSS_ISOLATION\n",
      "- OFF_POSS_MISC\n",
      "- OFF_POSS_OFFREBOUND\n",
      "- OFF_POSS_OFFSCREEN\n",
      "- OFF_POSS_PRBALLHANDLER\n",
      "- OFF_POSS_PRROLLMAN\n",
      "- OFF_POSS_POSTUP\n",
      "- OFF_POSS_SPOTUP\n",
      "- OFF_POSS_TRANSITION\n",
      "- OFF_PPP_CUT\n",
      "- OFF_PPP_HANDOFF\n",
      "- OFF_PPP_ISOLATION\n",
      "- OFF_PPP_MISC\n",
      "- OFF_PPP_OFFREBOUND\n",
      "- OFF_PPP_OFFSCREEN\n",
      "- OFF_PPP_PRBALLHANDLER\n",
      "- OFF_PPP_PRROLLMAN\n",
      "- OFF_PPP_POSTUP\n",
      "- OFF_PPP_SPOTUP\n",
      "defensive_play_types:\n",
      "- DEF_POSS_HANDOFF\n",
      "- DEF_POSS_ISOLATION\n",
      "- DEF_POSS_OFFSCREEN\n",
      "- DEF_POSS_PRBALLHANDLER\n",
      "- DEF_POSS_PRROLLMAN\n",
      "- DEF_POSS_POSTUP\n",
      "- DEF_POSS_SPOTUP\n",
      "- DEF_PPP_HANDOFF\n",
      "- DEF_PPP_ISOLATION\n",
      "- DEF_PPP_OFFSCREEN\n",
      "- DEF_PPP_PRBALLHANDLER\n",
      "- DEF_PPP_PRROLLMAN\n",
      "- DEF_PPP_POSTUP\n",
      "- DEF_PPP_SPOTUP\n",
      "- DEF_EFG_PCT_HANDOFF\n",
      "- DEF_EFG_PCT_ISOLATION\n",
      "- DEF_EFG_PCT_OFFSCREEN\n",
      "- DEF_EFG_PCT_PRBALLHANDLER\n",
      "- DEF_EFG_PCT_PRROLLMAN\n",
      "- DEF_EFG_PCT_POSTUP\n",
      "- DEF_EFG_PCT_SPOTUP\n",
      "- DEF_FG_PCT_HANDOFF\n",
      "- DEF_FG_PCT_ISOLATION\n",
      "- DEF_FG_PCT_OFFSCREEN\n",
      "- DEF_FG_PCT_PRBALLHANDLER\n",
      "- DEF_FG_PCT_PRROLLMAN\n",
      "- DEF_FG_PCT_POSTUP\n",
      "- DEF_FG_PCT_SPOTUP\n",
      "- DEF_FT_POSS_PCT_HANDOFF\n",
      "- DEF_FT_POSS_PCT_ISOLATION\n",
      "- DEF_FT_POSS_PCT_OFFSCREEN\n",
      "- DEF_FT_POSS_PCT_PRBALLHANDLER\n",
      "- DEF_FT_POSS_PCT_POSTUP\n",
      "- DEF_FT_POSS_PCT_SPOTUP\n",
      "usage_related:\n",
      "- TRUE_USAGE%\n",
      "- TURNOVER_USAGE%\n",
      "- PLAYMAKING_USAGE%\n",
      "- SCORING_USAGE%\n",
      "- OFFENSIVE_LOAD%\n",
      "miscellaneous:\n",
      "- portability_score\n",
      "- TEAM_POSS\n",
      "- TOTAL_DAYS_INJURED\n",
      "target:\n",
      "- AAV_PCT_OF_MAX\n",
      "\n",
      "[load_schema] resolved numerical_categories_flat keys: ['general', 'scoring', 'advanced', 'playmaking', 'rebounding', 'defense', 'usage', 'rankings', 'team', 'efficiency', 'hustle_boxouts', 'offensive_play_types', 'defensive_play_types', 'usage_related', 'miscellaneous']\n",
      "✓ Loaded column schema\n",
      "[train] Random split: train=1564, test=391\n",
      "✓ Fitted preprocessor: (1564, 359)\n",
      "✓ Saved FeatureSpec for Bayesian model\n",
      "[bayes] target='AAV' rows=1564  missing_target=0\n",
      "[bayes] numerical(253): ['2P', '2P%', '2PA', '3P', '3P%', '3PA', '3PAR', 'AGE', 'AST', 'AST%']\n",
      "[bayes] nominal(3): ['POSITION', 'cap_space_tier', 'market_tier']\n",
      "[bayes] ordinal(1): ['experience_bucket']\n",
      "[bayes] numeric missing before impute: 11206\n",
      "[bayes] X shape after concat: (1564, 269)\n",
      "[bayes] group='POSITION' levels=7\n",
      "[bayes] group='SEASON' levels=10\n",
      "[bayes] group='PLAYER_ID' levels=770\n",
      "[bayes] group='TEAM_ID' levels=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO:pymc.sampling.mcmc:Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "INFO:pymc.sampling.mcmc:Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [beta, alpha, sigma, a_POSITION, a_SEASON, a_PLAYER_ID, a_TEAM_ID]\n",
      "INFO:pymc.sampling.mcmc:NUTS: [beta, alpha, sigma, a_POSITION, a_SEASON, a_PLAYER_ID, a_TEAM_ID]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b75d3231704299a73dec4598b1c601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 19 seconds.\n",
      "INFO:pymc.sampling.mcmc:Sampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 19 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "INFO:pymc.stats.convergence:We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "INFO:pymc.stats.convergence:The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bayesian posterior saved → api/src/ml/data/ml_artifacts/bayes_hier_AAV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning:\n",
      "\n",
      "'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian holdout: RMSE=9795288.3980  MAE=5660712.3244  R2=-0.5011\n",
      "✓ Bayesian smoke completed → api/src/ml/data/ml_artifacts/bayes_hier_AAV/posterior.nc\n",
      "✓ Artifact file exists\n",
      "\n",
      "=== SMOKE SUMMARY ===\n",
      "bayes_hier_posterior: api/src/ml/data/ml_artifacts/bayes_hier_AAV/posterior.nc\n",
      "✅ Enhanced Bayesian smoke finished.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile api/src/ml/bayes_hier.py\n",
    "# FIXED api/src/ml/bayes_hier.py - Addresses all major issues\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from api.src.ml import config\n",
    "from api.src.ml.config import TrainingConfig, get_master_parquet_path\n",
    "\n",
    "ARTIFACTS_DIR = config.ARTIFACTS_DIR\n",
    "\n",
    "from api.src.ml.preprocessing.feature_store.spec_builder import FeatureSpec\n",
    "from dataclasses import dataclass\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "@dataclass\n",
    "class DesignSpec:\n",
    "    num_imputer: SimpleImputer\n",
    "    num_scaler: RobustScaler  # Changed to RobustScaler for better outlier handling\n",
    "    ohe: OneHotEncoder\n",
    "    num_cols: list[str]\n",
    "    nom_cols: list[str]\n",
    "    ord_cols: list[str]\n",
    "    group_levels: dict[str, list[str]]\n",
    "    y_mean: float\n",
    "    y_std: float\n",
    "    y_median: float  # Added for robust scaling info\n",
    "    y_iqr: float     # Added for robust scaling info\n",
    "\n",
    "    def save(self, path: Path) -> None:\n",
    "        path = Path(path)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        joblib.dump(self, path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path: Path) -> \"DesignSpec\":\n",
    "        return joblib.load(path)\n",
    "\n",
    "def _resolve_group_cols_case_insensitive(df: pd.DataFrame, group_cols: Sequence[str]) -> list[str]:\n",
    "    \"\"\"Fix case sensitivity issues in group column resolution\"\"\"\n",
    "    print(f\"[bayes] Resolving group columns: {group_cols}\")\n",
    "    available_cols = df.columns.tolist()\n",
    "    resolved = []\n",
    "    \n",
    "    for gcol in group_cols:\n",
    "        # Try exact match first\n",
    "        if gcol in available_cols:\n",
    "            resolved.append(gcol)\n",
    "            print(f\"[bayes] ✓ Exact match: {gcol}\")\n",
    "            continue\n",
    "            \n",
    "        # Try case variations\n",
    "        variations = [gcol.upper(), gcol.lower(), gcol.title()]\n",
    "        found = False\n",
    "        for var in variations:\n",
    "            if var in available_cols:\n",
    "                resolved.append(var)\n",
    "                print(f\"[bayes] ✓ Case-insensitive match: {gcol} -> {var}\")\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            # Try partial matches\n",
    "            partial_matches = [c for c in available_cols if gcol.lower() in c.lower()]\n",
    "            if partial_matches:\n",
    "                best_match = min(partial_matches, key=len)  # Shortest match\n",
    "                resolved.append(best_match)\n",
    "                print(f\"[bayes] ✓ Partial match: {gcol} -> {best_match}\")\n",
    "            else:\n",
    "                print(f\"[bayes] ❌ Not found: {gcol}\")\n",
    "    \n",
    "    return resolved\n",
    "\n",
    "def _validate_and_fix_target(df: pd.DataFrame, target: str, debug_dir: Path = None) -> tuple[pd.DataFrame, str]:\n",
    "    \"\"\"Validate and fix target variable issues\"\"\"\n",
    "    print(f\"[bayes] Validating target variable: {target}\")\n",
    "    \n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataframe\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    target_stats = df[target].describe()\n",
    "    print(f\"[bayes] Target statistics:\\n{target_stats}\")\n",
    "    \n",
    "    # Check for issues\n",
    "    issues = []\n",
    "    df_fixed = df.copy()\n",
    "    \n",
    "    # 1. Check for extreme outliers (likely unit errors)\n",
    "    q99 = df[target].quantile(0.99)\n",
    "    q01 = df[target].quantile(0.01)\n",
    "    \n",
    "    if df[target].max() > q99 * 20:  # Values more than 20x the 99th percentile\n",
    "        extreme_outliers = (df[target] > q99 * 10).sum()\n",
    "        issues.append(f\"Extreme outliers detected: {extreme_outliers} values > 10x Q99\")\n",
    "        \n",
    "        # Cap extreme outliers at 3x Q99\n",
    "        cap_value = q99 * 3\n",
    "        df_fixed[target] = df_fixed[target].clip(upper=cap_value)\n",
    "        print(f\"[bayes] Capped {extreme_outliers} extreme outliers at ${cap_value:,.0f}\")\n",
    "    \n",
    "    # 2. Check for negative values in salary data\n",
    "    if (df[target] < 0).any():\n",
    "        negative_count = (df[target] < 0).sum()\n",
    "        issues.append(f\"Negative values detected: {negative_count}\")\n",
    "        df_fixed = df_fixed[df_fixed[target] >= 0]\n",
    "        print(f\"[bayes] Removed {negative_count} rows with negative target values\")\n",
    "    \n",
    "    # 3. Check if values seem to be in wrong units (NBA salaries should be $1M-$50M range)\n",
    "    median_val = df_fixed[target].median()\n",
    "    if median_val > 50_000_000:  # More than $50M median suggests wrong units\n",
    "        print(f\"[bayes] Target values seem too high (median=${median_val:,.0f})\")\n",
    "        print(\"[bayes] Consider checking data source units\")\n",
    "    elif median_val < 100_000:  # Less than $100K median also suspicious\n",
    "        print(f\"[bayes] Target values seem too low (median=${median_val:,.0f})\")\n",
    "        print(\"[bayes] Consider checking data source units\")\n",
    "    \n",
    "    # 4. Remove missing target values\n",
    "    missing_target = df_fixed[target].isnull().sum()\n",
    "    if missing_target > 0:\n",
    "        df_fixed = df_fixed.dropna(subset=[target])\n",
    "        issues.append(f\"Missing target values removed: {missing_target}\")\n",
    "        print(f\"[bayes] Removed {missing_target} rows with missing target\")\n",
    "    \n",
    "    # Save debug info if requested\n",
    "    if debug_dir:\n",
    "        debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "        with open(debug_dir / \"target_validation.txt\", \"w\") as f:\n",
    "            f.write(f\"Target: {target}\\n\")\n",
    "            f.write(f\"Original shape: {df.shape}\\n\")\n",
    "            f.write(f\"Fixed shape: {df_fixed.shape}\\n\")\n",
    "            f.write(f\"Issues found: {issues}\\n\")\n",
    "            f.write(f\"Final statistics:\\n{df_fixed[target].describe()}\\n\")\n",
    "    \n",
    "    return df_fixed, target\n",
    "\n",
    "def _prepare_design(\n",
    "    df: pd.DataFrame, \n",
    "    spec: FeatureSpec, \n",
    "    group_cols: Sequence[str] = (),\n",
    "    verbose: bool = False,\n",
    "    design: Optional[DesignSpec] = None,\n",
    "    strict_design: bool = False,\n",
    "    debug_dir: Path = None\n",
    ") -> tuple[np.ndarray, list[str], np.ndarray, dict, DesignSpec]:\n",
    "    \"\"\"Enhanced design preparation with better data handling\"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[bayes] target='{spec.target}' rows={len(df)}  missing_target={df[spec.target].isnull().sum()}\")\n",
    "    \n",
    "    # Validate and fix target first\n",
    "    df_clean, target = _validate_and_fix_target(df, spec.target, debug_dir)\n",
    "    y_raw = df_clean[target].astype(float).values\n",
    "    \n",
    "    if len(y_raw) == 0:\n",
    "        raise ValueError(\"[bayes] No valid target values after cleaning\")\n",
    "    \n",
    "    # Enhanced feature selection - be more aggressive to prevent overfitting\n",
    "    all_feature_cols = [c for c in df_clean.columns if c in spec.final_features and c != target]\n",
    "    \n",
    "    # Filter out features with too much missing data or low variance\n",
    "    good_features = []\n",
    "    for col in all_feature_cols:\n",
    "        missing_pct = df_clean[col].isnull().sum() / len(df_clean)\n",
    "        if missing_pct > 0.5:  # Skip features with >50% missing\n",
    "            if verbose:\n",
    "                print(f\"[bayes] Skipping {col}: {missing_pct:.1%} missing\")\n",
    "            continue\n",
    "            \n",
    "        if df_clean[col].dtype in ['object', 'category']:\n",
    "            good_features.append(col)\n",
    "        else:\n",
    "            # Check variance for numeric features\n",
    "            var = df_clean[col].var()\n",
    "            if pd.notna(var) and var > 0:\n",
    "                good_features.append(col)\n",
    "            elif verbose:\n",
    "                print(f\"[bayes] Skipping {col}: zero variance\")\n",
    "    \n",
    "    # Limit total features to prevent overfitting\n",
    "    MAX_FEATURES = 50  # Conservative limit for Bayesian model\n",
    "    if len(good_features) > MAX_FEATURES:\n",
    "        # Select features by correlation with target\n",
    "        numeric_features = [c for c in good_features if df_clean[c].dtype in ['int64', 'float64']]\n",
    "        if len(numeric_features) > 0:\n",
    "            correlations = df_clean[numeric_features + [target]].corr()[target].abs()\n",
    "            top_features = correlations.nlargest(MAX_FEATURES).index.tolist()\n",
    "            if target in top_features:\n",
    "                top_features.remove(target)\n",
    "            good_features = top_features[:MAX_FEATURES]\n",
    "            if verbose:\n",
    "                print(f\"[bayes] Reduced to top {len(good_features)} features by correlation\")\n",
    "        else:\n",
    "            good_features = good_features[:MAX_FEATURES]\n",
    "    \n",
    "    # Separate by type\n",
    "    num_cols = [c for c in good_features if df_clean[c].dtype in ['int64', 'float64']]\n",
    "    nom_cols = [c for c in good_features if df_clean[c].dtype in ['object', 'category'] and c not in num_cols]\n",
    "    ord_cols = []  # Simplified: treat ordinal as numeric for now\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[bayes] numerical({len(num_cols)}): {num_cols[:10]}\")\n",
    "        print(f\"[bayes] nominal({len(nom_cols)}): {nom_cols}\")\n",
    "        print(f\"[bayes] ordinal({len(ord_cols)}): {ord_cols}\")\n",
    "    \n",
    "    # Handle training vs prediction\n",
    "    if design is None:  # Training mode\n",
    "        # Numeric preprocessing with robust scaling\n",
    "        if num_cols:\n",
    "            num_imputer = SimpleImputer(strategy='median')  # More robust than mean\n",
    "            X_num = num_imputer.fit_transform(df_clean[num_cols])\n",
    "            \n",
    "            # Use RobustScaler instead of StandardScaler for better outlier handling\n",
    "            num_scaler = RobustScaler()\n",
    "            X_num = num_scaler.fit_transform(X_num)\n",
    "            \n",
    "            missing_before = df_clean[num_cols].isnull().sum().sum()\n",
    "            if verbose and missing_before > 0:\n",
    "                print(f\"[bayes] numeric missing before impute: {missing_before}\")\n",
    "        else:\n",
    "            num_imputer = SimpleImputer()\n",
    "            num_scaler = RobustScaler()\n",
    "            X_num = np.empty((len(df_clean), 0))\n",
    "        \n",
    "        # Nominal preprocessing\n",
    "        if nom_cols:\n",
    "            # Fill missing with 'Missing' category\n",
    "            df_nom = df_clean[nom_cols].fillna('Missing').astype(str)\n",
    "            ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "            X_nom = ohe.fit_transform(df_nom)\n",
    "        else:\n",
    "            ohe = OneHotEncoder()\n",
    "            X_nom = np.empty((len(df_clean), 0))\n",
    "        \n",
    "        # Combine features\n",
    "        X = np.concatenate([X_num, X_nom], axis=1)\n",
    "        \n",
    "        # Feature names\n",
    "        num_names = num_cols\n",
    "        nom_names = ohe.get_feature_names_out(nom_cols) if nom_cols else []\n",
    "        feat_names = list(num_names) + list(nom_names)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"[bayes] X shape after concat: {X.shape}\")\n",
    "        \n",
    "        # Target preprocessing - robust standardization\n",
    "        y_median = np.median(y_raw)\n",
    "        y_q75 = np.percentile(y_raw, 75)\n",
    "        y_q25 = np.percentile(y_raw, 25)\n",
    "        y_iqr = y_q75 - y_q25\n",
    "        \n",
    "        if y_iqr == 0:\n",
    "            y_mean = np.mean(y_raw)\n",
    "            y_std = np.std(y_raw)\n",
    "            if y_std == 0:\n",
    "                raise ValueError(\"[bayes] Target has zero variance\")\n",
    "        else:\n",
    "            y_mean = y_median  # Use median instead of mean for robustness\n",
    "            y_std = y_iqr      # Use IQR instead of std for robustness\n",
    "            \n",
    "        # Create design spec\n",
    "        design = DesignSpec(\n",
    "            num_imputer=num_imputer,\n",
    "            num_scaler=num_scaler,\n",
    "            ohe=ohe,\n",
    "            num_cols=num_cols,\n",
    "            nom_cols=nom_cols,\n",
    "            ord_cols=ord_cols,\n",
    "            group_levels={},  # Will be populated below\n",
    "            y_mean=y_mean,\n",
    "            y_std=y_std,\n",
    "            y_median=y_median,\n",
    "            y_iqr=y_iqr,\n",
    "        )\n",
    "        \n",
    "    else:  # Prediction mode - use existing design\n",
    "        num_cols = design.num_cols\n",
    "        nom_cols = design.nom_cols\n",
    "        ord_cols = design.ord_cols\n",
    "        \n",
    "        if num_cols:\n",
    "            X_num = design.num_imputer.transform(df_clean[num_cols])\n",
    "            X_num = design.num_scaler.transform(X_num)\n",
    "        else:\n",
    "            X_num = np.empty((len(df_clean), 0))\n",
    "            \n",
    "        if nom_cols:\n",
    "            df_nom = df_clean[nom_cols].fillna('Missing').astype(str)\n",
    "            X_nom = design.ohe.transform(df_nom)\n",
    "        else:\n",
    "            X_nom = np.empty((len(df_clean), 0))\n",
    "            \n",
    "        X = np.concatenate([X_num, X_nom], axis=1)\n",
    "        \n",
    "        num_names = design.num_cols\n",
    "        nom_names = design.ohe.get_feature_names_out(design.nom_cols) if design.nom_cols else []\n",
    "        feat_names = list(num_names) + list(nom_names)\n",
    "    \n",
    "    # Handle group columns with improved resolution\n",
    "    resolved_group_cols = _resolve_group_cols_case_insensitive(df_clean, group_cols)\n",
    "    groups = {}\n",
    "    \n",
    "    for gcol in resolved_group_cols:\n",
    "        if gcol in df_clean.columns:\n",
    "            group_series = df_clean[gcol].astype(str).fillna(\"Missing\")\n",
    "            if design is None:  # Training\n",
    "                levels = sorted(group_series.unique())\n",
    "                design.group_levels[gcol] = levels\n",
    "            else:  # Prediction\n",
    "                levels = design.group_levels.get(gcol, [])\n",
    "            \n",
    "            # Map to indices, handling unseen levels\n",
    "            level_to_idx = {level: i for i, level in enumerate(levels)}\n",
    "            indices = group_series.map(level_to_idx).fillna(-1).astype(int).values\n",
    "            \n",
    "            groups[gcol] = {\"levels\": levels, \"index\": indices}\n",
    "            \n",
    "            if verbose:\n",
    "                n_levels = len(levels)\n",
    "                n_unseen = (indices == -1).sum()\n",
    "                print(f\"[bayes] group='{gcol}' levels={n_levels}\")\n",
    "                if n_unseen > 0:\n",
    "                    print(f\"[bayes] group='{gcol}' unseen_levels={n_unseen}\")\n",
    "    \n",
    "    return X, feat_names, y_raw, groups, design\n",
    "\n",
    "def train_bayesian(\n",
    "    df: pd.DataFrame,\n",
    "    spec: FeatureSpec,\n",
    "    draws: int = 1000,\n",
    "    tune: int = 1000,\n",
    "    target_accept: float = 0.95,\n",
    "    chains: int = 4,  # Increased from 2 for better convergence\n",
    "    cores: int = 4,\n",
    "    group_cols: Sequence[str] = (),\n",
    "    random_seed: int = 42,\n",
    "    out_dir: Optional[Path] = None,\n",
    "    compute_loo: bool = False,\n",
    "    strict_design: bool = False,\n",
    ") -> tuple[Path, az.InferenceData]:\n",
    "    \"\"\"\n",
    "    Enhanced Bayesian training with robust preprocessing and better error handling.\n",
    "    \"\"\"\n",
    "    # Resolve group cols early to catch issues\n",
    "    group_cols = _resolve_group_cols_case_insensitive(df, group_cols)\n",
    "    if len(group_cols) == 0:\n",
    "        print(\"[bayes][warn] no valid group columns resolved; proceeding with fixed-effects only\")\n",
    "\n",
    "    debug_dir = (out_dir or (ARTIFACTS_DIR / f\"bayes_hier_{spec.target}\")) / \"debug\"\n",
    "    X, feat_names, y_raw, groups, design = _prepare_design(\n",
    "        df, spec, group_cols=group_cols, verbose=True, design=None,\n",
    "        strict_design=strict_design, debug_dir=debug_dir\n",
    "    )\n",
    "\n",
    "    # Enhanced target standardization using robust scaling\n",
    "    y_mean, y_std = design.y_mean, design.y_std\n",
    "    if y_std == 0 or not np.isfinite(y_std):\n",
    "        raise ValueError(f\"[bayes/train] y has zero or non-finite std ({y_std}); cannot standardize.\")\n",
    "    \n",
    "    y = (y_raw - y_mean) / y_std\n",
    "    \n",
    "    # Additional validation\n",
    "    if not np.isfinite(y).all():\n",
    "        print(f\"[bayes][warn] Non-finite values in standardized y: {(~np.isfinite(y)).sum()}\")\n",
    "        finite_mask = np.isfinite(y)\n",
    "        X = X[finite_mask]\n",
    "        y = y[finite_mask]\n",
    "        for gname, gobj in groups.items():\n",
    "            groups[gname][\"index\"] = gobj[\"index\"][finite_mask]\n",
    "    \n",
    "    print(f\"[bayes] Final training shape: X={X.shape}, y={y.shape}\")\n",
    "    \n",
    "    coords = {\"obs\": np.arange(len(y)), \"feat\": np.arange(X.shape[1])}\n",
    "    for gname, gobj in groups.items():\n",
    "        coords[gname] = np.arange(len(gobj[\"levels\"]))\n",
    "\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # More conservative priors to prevent divergences\n",
    "        beta = pm.Normal(\"beta\", 0.0, 0.5, dims=(\"feat\",))  # Tighter prior\n",
    "        alpha = pm.Normal(\"alpha\", 0.0, 1.0)\n",
    "\n",
    "        # Non-centered random intercepts with more conservative priors\n",
    "        mu = alpha + pm.math.dot(X, beta)\n",
    "        for gname, gobj in groups.items():\n",
    "            eta = pm.Normal(f\"eta_{gname}\", 0.0, 1.0, dims=(gname,))\n",
    "            tau = pm.HalfNormal(f\"tau_{gname}\", 0.5)  # More conservative prior\n",
    "            a_g = pm.Deterministic(f\"a_{gname}\", tau * eta, dims=(gname,))\n",
    "            mu = mu + a_g[gobj[\"index\"]]\n",
    "\n",
    "        # More robust likelihood\n",
    "        sigma = pm.HalfNormal(\"sigma\", 1.0)\n",
    "        nu = pm.Exponential(\"nu\", 1/10) + 2.1  # Slightly higher nu for stability\n",
    "        pm.StudentT(\"y_obs\", nu=nu, mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "        # Enhanced sampling with better initialization\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            idata = pm.sample(\n",
    "                draws=draws, tune=tune, target_accept=target_accept,\n",
    "                chains=chains, cores=cores, random_seed=random_seed,\n",
    "                return_inferencedata=True,\n",
    "                idata_kwargs={\"log_likelihood\": compute_loo},\n",
    "                init=\"adapt_diag\",  # Better initialization\n",
    "            )\n",
    "\n",
    "    out = out_dir or (ARTIFACTS_DIR / f\"bayes_hier_{spec.target}\")\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save all artifacts\n",
    "    az.to_netcdf(idata, out / \"posterior.nc\")\n",
    "    (out / \"feature_names.txt\").write_text(\"\\n\".join(feat_names))\n",
    "\n",
    "    import json\n",
    "    (out / \"config_groups.json\").write_text(json.dumps({k: v[\"levels\"] for k, v in groups.items()}, indent=2))\n",
    "\n",
    "    # Save the design for consistent predict\n",
    "    design.save(out / \"design_spec.joblib\")\n",
    "\n",
    "    # Enhanced diagnostics\n",
    "    summary = az.summary(idata, var_names=[v for v in idata.posterior.data_vars], round_to=4)\n",
    "    summary.to_csv(out / \"sampling_summary.csv\")\n",
    "    \n",
    "    # Check convergence\n",
    "    max_rhat = float(summary[\"r_hat\"].max())\n",
    "    min_ess_bulk = float(summary[\"ess_bulk\"].min())\n",
    "    min_ess_tail = float(summary[\"ess_tail\"].min())\n",
    "    \n",
    "    print(f\"[bayes] Convergence diagnostics:\")\n",
    "    print(f\"  Max R-hat: {max_rhat:.4f} (should be < 1.01)\")\n",
    "    print(f\"  Min ESS bulk: {min_ess_bulk:.0f} (should be > 400)\")\n",
    "    print(f\"  Min ESS tail: {min_ess_tail:.0f} (should be > 400)\")\n",
    "    \n",
    "    if max_rhat > 1.01:\n",
    "        print(\"[bayes][WARN] Poor convergence (R-hat > 1.01). Consider:\")\n",
    "        print(\"  - Increasing draws/tune\")\n",
    "        print(\"  - Using more conservative priors\")\n",
    "        print(\"  - Checking for numerical issues in data\")\n",
    "    \n",
    "    if min_ess_bulk < 400 or min_ess_tail < 400:\n",
    "        print(\"[bayes][WARN] Low effective sample size. Consider:\")\n",
    "        print(\"  - Increasing draws\")\n",
    "        print(\"  - Checking for poor mixing\")\n",
    "\n",
    "    if compute_loo:\n",
    "        try:\n",
    "            comp = az.loo(idata)\n",
    "            comp.to_dataframe().to_csv(out / \"loo_summary.csv\")\n",
    "            print(f\"[bayes] LOO-CV: {comp.elpd_loo:.2f} ± {comp.se:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[bayes][warn] LOO computation failed: {e}\")\n",
    "\n",
    "    # Save debug information\n",
    "    debug_info = {\n",
    "        \"original_features\": len(spec.final_features),\n",
    "        \"selected_features\": len(feat_names),\n",
    "        \"original_rows\": len(df),\n",
    "        \"final_rows\": len(y),\n",
    "        \"target_stats\": {\n",
    "            \"mean\": float(y_mean),\n",
    "            \"std\": float(y_std),\n",
    "            \"min\": float(y_raw.min()),\n",
    "            \"max\": float(y_raw.max()),\n",
    "        },\n",
    "        \"convergence\": {\n",
    "            \"max_rhat\": float(max_rhat),\n",
    "            \"min_ess_bulk\": float(min_ess_bulk),\n",
    "            \"min_ess_tail\": float(min_ess_tail),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(out / \"debug_info.json\", \"w\") as f:\n",
    "        json.dump(debug_info, f, indent=2)\n",
    "\n",
    "    return out, idata\n",
    "\n",
    "def predict_bayesian(\n",
    "    df: pd.DataFrame,\n",
    "    spec: FeatureSpec,\n",
    "    artifact_dir: Path,\n",
    "    group_cols: Sequence[str] = (),\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Enhanced prediction with better error handling and validation.\n",
    "    \"\"\"\n",
    "    artifact_dir = Path(artifact_dir)\n",
    "    \n",
    "    # Load design and validate\n",
    "    design_path = artifact_dir / \"design_spec.joblib\"\n",
    "    if not design_path.exists():\n",
    "        raise FileNotFoundError(f\"Design spec not found: {design_path}\")\n",
    "    \n",
    "    design = DesignSpec.load(design_path)\n",
    "\n",
    "    # Use the training's canonical group columns\n",
    "    X, feat_names, y_raw, groups, _ = _prepare_design(\n",
    "        df, spec, group_cols=list(design.group_levels.keys()), verbose=False,\n",
    "        design=design, strict_design=False, debug_dir=artifact_dir / \"debug\"\n",
    "    )\n",
    "\n",
    "    # Load posterior\n",
    "    posterior_path = artifact_dir / \"posterior.nc\"\n",
    "    if not posterior_path.exists():\n",
    "        raise FileNotFoundError(f\"Posterior not found: {posterior_path}\")\n",
    "    \n",
    "    idata = az.from_netcdf(posterior_path)\n",
    "    post = idata.posterior\n",
    "    \n",
    "    # Extract parameters\n",
    "    beta = post[\"beta\"].stack(sample=(\"chain\", \"draw\")).values\n",
    "    alpha = post[\"alpha\"].stack(sample=(\"chain\", \"draw\")).values\n",
    "    \n",
    "    # Validate dimensions\n",
    "    if X.shape[1] != beta.shape[0]:\n",
    "        raise ValueError(f\"Feature dimension mismatch: X has {X.shape[1]} features, model expects {beta.shape[0]}\")\n",
    "    \n",
    "    # Compute predictions\n",
    "    mu = X @ beta + alpha\n",
    "\n",
    "    # Add group effects with safe indexing\n",
    "    for gname, gobj in groups.items():\n",
    "        if f\"a_{gname}\" in post:\n",
    "            a_g = post[f\"a_{gname}\"].stack(sample=(\"chain\", \"draw\")).values\n",
    "            idx = gobj[\"index\"]\n",
    "            \n",
    "            # Safe indexing for group effects\n",
    "            eff = np.zeros((len(idx), a_g.shape[1]))\n",
    "            mask = (idx >= 0) & (idx < len(a_g))\n",
    "            if mask.any():\n",
    "                eff[mask, :] = a_g[idx[mask], :]\n",
    "            mu += eff\n",
    "        else:\n",
    "            print(f\"[bayes][warn] Group effect '{gname}' not found in posterior\")\n",
    "\n",
    "    # Convert back to original scale\n",
    "    pred_std_mean = mu.mean(axis=1)\n",
    "    y_mean, y_std = design.y_mean, design.y_std\n",
    "    pred = pred_std_mean * y_std + y_mean\n",
    "    \n",
    "    # Validation\n",
    "    if not np.isfinite(pred).all():\n",
    "        print(f\"[bayes][warn] Non-finite predictions: {(~np.isfinite(pred)).sum()}\")\n",
    "        pred = np.where(np.isfinite(pred), pred, y_mean)  # Replace with mean\n",
    "    \n",
    "    return pd.Series(pred, index=df.index, name=f\"pred_{spec.target}\")\n",
    "\n",
    "# DEBUGGING AND VALIDATION FUNCTIONS\n",
    "\n",
    "def debug_env_report():\n",
    "    \"\"\"Print versions & environment facts helpful for Bayesian runs.\"\"\"\n",
    "    import sys\n",
    "    import sklearn\n",
    "    print(\"[env] python:\", sys.version.replace(\"\\n\", \" \"))\n",
    "    print(\"[env] pymc:\", pm.__version__)\n",
    "    print(\"[env] arviz:\", az.__version__)\n",
    "    print(\"[env] numpy:\", np.__version__)\n",
    "    print(\"[env] sklearn:\", sklearn.__version__)\n",
    "    \n",
    "    try:\n",
    "        import shutil\n",
    "        has_gpp = shutil.which(\"g++\") is not None\n",
    "        print(f\"[env] g++ available: {has_gpp}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[env] g++ check failed: {e} (non-fatal)\")\n",
    "\n",
    "def validate_data_before_training(df: pd.DataFrame, target: str) -> dict:\n",
    "    \"\"\"Comprehensive data validation before training\"\"\"\n",
    "    print(\"=== DATA VALIDATION BEFORE TRAINING ===\")\n",
    "    \n",
    "    issues = {}\n",
    "    \n",
    "    # Check target variable\n",
    "    if target not in df.columns:\n",
    "        issues['missing_target'] = f\"Target '{target}' not in columns\"\n",
    "        return issues\n",
    "    \n",
    "    target_stats = df[target].describe()\n",
    "    print(f\"Target '{target}' statistics:\")\n",
    "    print(target_stats)\n",
    "    \n",
    "    # Check for concerning patterns\n",
    "    if df[target].isnull().sum() > len(df) * 0.1:\n",
    "        issues['high_target_missing'] = f\"Target has {df[target].isnull().sum()} missing values\"\n",
    "    \n",
    "    if df[target].std() == 0:\n",
    "        issues['zero_variance_target'] = \"Target has zero variance\"\n",
    "    \n",
    "    # Check extreme outliers\n",
    "    q99 = df[target].quantile(0.99)\n",
    "    extreme_outliers = (df[target] > q99 * 10).sum()\n",
    "    if extreme_outliers > 0:\n",
    "        issues['extreme_outliers'] = f\"{extreme_outliers} extreme outliers (>10x Q99)\"\n",
    "    \n",
    "    # Check feature matrix\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 100:\n",
    "        issues['too_many_features'] = f\"High feature count: {len(numeric_cols)} numeric columns\"\n",
    "    \n",
    "    # Check missing data patterns\n",
    "    high_missing = (df.isnull().sum() / len(df) > 0.5).sum()\n",
    "    if high_missing > 10:\n",
    "        issues['high_missing_features'] = f\"{high_missing} features with >50% missing data\"\n",
    "    \n",
    "    if len(issues) == 0:\n",
    "        print(\"✓ No major data issues detected\")\n",
    "    else:\n",
    "        print(\"⚠️ Issues detected:\")\n",
    "        for issue, desc in issues.items():\n",
    "            print(f\"  {issue}: {desc}\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "def run_bayes_realdata_smoke() -> dict:\n",
    "    \"\"\"Enhanced smoke test with comprehensive validation and debugging\"\"\"\n",
    "    from api.src.ml.config import validate_configuration, get_master_parquet_path\n",
    "    from api.src.ml import config as _cfg\n",
    "\n",
    "    debug_env_report()\n",
    "\n",
    "    # 0) Validate wiring\n",
    "    ok = validate_configuration()\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"[smoke] Configuration validation failed.\")\n",
    "    print(\"✓ Configuration validated\")\n",
    "\n",
    "    # 1) Dataset preflight\n",
    "    data_path = get_master_parquet_path()\n",
    "    alt_path = _cfg.FINAL_ENGINEERED_DATASET_DIR / \"final_merged_with_all.parquet\"\n",
    "    path_to_use = data_path if data_path.exists() else (alt_path if alt_path.exists() else None)\n",
    "    if path_to_use is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"[smoke] Real dataset not found at {data_path} or {alt_path}. \"\n",
    "            \"Generate engineered parquet before smoke.\"\n",
    "        )\n",
    "    print(f\"✓ Real dataset exists → {path_to_use}\")\n",
    "\n",
    "    # 2) Load and validate data\n",
    "    import pandas as pd\n",
    "    df = pd.read_parquet(path_to_use)\n",
    "    print(f\"[smoke] Loaded dataset: {df.shape}\")\n",
    "\n",
    "    # Validate data quality\n",
    "    issues = validate_data_before_training(df, \"AAV\")\n",
    "    if len(issues) > 3:  # Too many issues\n",
    "        print(\"⚠️ Too many data quality issues, proceeding with fixes...\")\n",
    "\n",
    "    # 3) Build conservative Bayesian config\n",
    "    from api.src.ml.config import TrainingConfig\n",
    "    bayes_cfg = TrainingConfig(\n",
    "        model_family=\"bayes_hier\",\n",
    "        target=\"AAV\",\n",
    "        max_train_rows=3000,  # Even smaller for smoke test\n",
    "        random_state=42,\n",
    "        bayes_draws=1000,     # Reduced for faster smoke\n",
    "        bayes_tune=1000,\n",
    "        bayes_target_accept=0.9,\n",
    "        bayes_chains=2,       # Keep at 2 for speed, but will warn\n",
    "        bayes_cores=2,\n",
    "        bayes_group_cols=(\"POSITION\", \"SEASON\", \"PLAYER_ID\", \"TEAM_ID\"),  # Fixed case\n",
    "    )\n",
    "    print(f\"[smoke] using cfg: {bayes_cfg}\")\n",
    "\n",
    "    # 4) Run training with proper error handling\n",
    "    from api.src.ml.train import train as _train\n",
    "\n",
    "    print(\"[smoke] Running Bayesian training...\")\n",
    "    try:\n",
    "        bayes_artifact = _train(bayes_cfg)\n",
    "        print(f\"✓ Bayesian smoke completed → {bayes_artifact}\")\n",
    "        \n",
    "        # Validate output\n",
    "        if isinstance(bayes_artifact, Path) and bayes_artifact.exists():\n",
    "            print(\"✓ Artifact file exists\")\n",
    "        else:\n",
    "            print(f\"⚠️ Artifact validation failed: {bayes_artifact}\")\n",
    "            \n",
    "        return {\"bayes_hier_posterior\": str(bayes_artifact)}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"💥 Bayesian training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== ENHANCED BAYESIAN REAL-DATA SMOKE ===\")\n",
    "    try:\n",
    "        out = run_bayes_realdata_smoke()\n",
    "        print(\"\\n=== SMOKE SUMMARY ===\")\n",
    "        for k, v in out.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "        print(\"✅ Enhanced Bayesian smoke finished.\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"💥 Enhanced Bayesian smoke failed: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b541c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
